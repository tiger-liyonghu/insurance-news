"""
Global Insurance Fraud Intelligence Agent (GIFIA) v2.0 - äº‘ç«¯æƒ…æŠ¥ç«™
å¤š Agent åä½œæ¨¡å¼ï¼šScout -> Scraper -> Analyst -> Critic
è‡ªåŠ¨åŒ–æŠ“å–è„šæœ¬ï¼šä½¿ç”¨å¤š Agent åä½œæå‡æå–è´¨é‡
"""

import os
import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import requests
from supabase import create_client, Client
import google.generativeai as genai
from tavily import TavilyClient
from openai import OpenAI

# ==================== ç¯å¢ƒå˜é‡é…ç½® ====================

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # æ–°å¢ï¼šç”¨äº GPT-4o-mini
JINA_API_KEY = os.getenv("JINA_API_KEY")  # æ–°å¢ï¼šç”¨äº Jina Reader
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
tavily_client = TavilyClient(api_key=TAVILY_API_KEY)
genai.configure(api_key=GEMINI_API_KEY)
openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None


# ==================== Agent 1: The Scout (ä¾¦å¯Ÿå‘˜) ====================

class ScoutAgent:
    """
    ä¾¦å¯Ÿå‘˜ Agentï¼šè´Ÿè´£æœç´¢é«˜è´¨é‡çš„ä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹
    æ”¹è¿›ç‚¹ï¼š
    1. ä½¿ç”¨ advanced æœç´¢æ·±åº¦
    2. æ·»åŠ ä¸“ä¸šå…³é”®è¯æé«˜æœç´¢è´¨é‡
    3. åªæœç´¢å…·ä½“æ¡ˆä¾‹ï¼ˆæ’é™¤é€šç”¨æ–‡ç« ï¼‰
    4. ä¸“æ³¨äºå¯¿é™©ã€å¥åº·é™©ã€æ„å¤–é™©
    """
    
    def __init__(self, tavily_client: TavilyClient):
        self.client = tavily_client
        
        # ä¸“ä¸šå…³é”®è¯ï¼šç¡®ä¿æ‰¾åˆ°å…·ä½“æ¡ˆä¾‹è€Œéé€šç”¨æ–‡ç« 
        self.case_specific_keywords = [
            'charged with fraud',
            'convicted of fraud',
            'fraud case',
            'fraud scheme',
            'arrested for insurance fraud',
            'sentenced for insurance fraud',
            'court case insurance fraud',
            'prosecution insurance fraud'
        ]
        
        # ä¿é™©ç±»å‹å…³é”®è¯ï¼šåªå…³æ³¨å¯¿é™©ã€å¥åº·é™©ã€æ„å¤–é™©
        self.insurance_types = [
            'life insurance fraud',      # å¯¿é™©æ¬ºè¯ˆ
            'health insurance fraud',    # å¥åº·é™©æ¬ºè¯ˆ
            'accident insurance fraud',  # æ„å¤–é™©æ¬ºè¯ˆ
            'medical insurance fraud',   # åŒ»ç–—ä¿é™©æ¬ºè¯ˆï¼ˆå±äºå¥åº·é™©ï¼‰
            'disability insurance fraud' # ä¼¤æ®‹ä¿é™©æ¬ºè¯ˆï¼ˆå¯èƒ½å±äºæ„å¤–é™©ï¼‰
        ]
        
        # æ’é™¤å…³é”®è¯ï¼šæ’é™¤è´¢äº§ä¿é™©
        self.exclude_keywords = [
            'property insurance',
            'auto insurance fraud',
            'car insurance fraud',
            'vehicle insurance',
            'home insurance',
            'house insurance'
        ]
    
    def build_query(self, base_query: str = None) -> str:
        """
        æ„å»ºå¢å¼ºçš„æœç´¢æŸ¥è¯¢ï¼Œä¸“æ³¨äºå…·ä½“æ¡ˆä¾‹å’ŒæŒ‡å®šä¿é™©ç±»å‹
        ç®€åŒ–æŸ¥è¯¢ä»¥ç¬¦åˆ Tavily API çš„ 400 å­—ç¬¦é™åˆ¶
        
        å‚æ•°:
            base_query: åŸºç¡€æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
        
        è¿”å›:
            å¢å¼ºåçš„æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼ˆé™åˆ¶åœ¨ 400 å­—ç¬¦å†…ï¼‰
        """
        # ç²¾ç®€æ¡ˆä¾‹å…³é”®è¯ï¼ˆåªé€‰æ‹©æœ€å…³é”®çš„ï¼‰
        essential_case_keywords = [
            'charged with fraud',
            'convicted of fraud',
            'fraud case',
            'fraud scheme'
        ]
        case_keywords = " OR ".join(essential_case_keywords[:3])  # åªä½¿ç”¨å‰3ä¸ª
        
        # ç²¾ç®€ä¿é™©ç±»å‹å…³é”®è¯
        essential_insurance_types = [
            'life insurance fraud',
            'health insurance fraud',
            'accident insurance fraud'
        ]
        insurance_keywords = " OR ".join(essential_insurance_types)
        
        # æ„å»ºæŸ¥è¯¢ï¼šç®€åŒ–ç‰ˆï¼Œä½¿ç”¨æ›´çŸ­çš„æ ¼å¼
        # æ ¼å¼: (æ¡ˆä¾‹å…³é”®è¯) (ä¿é™©ç±»å‹) -è´¢äº§ä¿é™© 2025 2026
        enhanced_query = f"{case_keywords} {insurance_keywords} -property insurance -auto insurance 2025 2026"
        
        # ç¡®ä¿ä¸è¶…è¿‡ 400 å­—ç¬¦
        if len(enhanced_query) > 400:
            # å¦‚æœè¿˜æ˜¯å¤ªé•¿ï¼Œè¿›ä¸€æ­¥ç®€åŒ–
            enhanced_query = "life insurance fraud case OR health insurance fraud case OR accident insurance fraud case -property -auto 2025 2026"
        
        return enhanced_query
    
    def search(self, base_query: str = None, max_results: int = 15) -> List[Dict]:
        """
        æœç´¢å…¨çƒä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹ï¼ˆé«˜çº§æ¨¡å¼ï¼‰
        åªæœç´¢å…·ä½“æ¡ˆä¾‹ï¼Œæ’é™¤é€šç”¨æ–‡ç« 
        ä¸“æ³¨äºå¯¿é™©ã€å¥åº·é™©ã€æ„å¤–é™©
        
        å‚æ•°:
            base_query: åŸºç¡€æœç´¢å…³é”®è¯ï¼ˆä¸å†ä½¿ç”¨ï¼Œä¿ç•™ç”¨äºå…¼å®¹ï¼‰
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°ï¼ˆæœç´¢æ›´å¤šä»¥ç­›é€‰å·®å¼‚æ€§ï¼‰
        
        è¿”å›:
            ç­›é€‰åçš„æœç´¢ç»“æœåˆ—è¡¨ï¼Œç¡®ä¿æ¡ˆä¾‹å·®å¼‚æ€§å’Œç›¸å…³æ€§
        """
        try:
            enhanced_query = self.build_query(base_query)
            
            print(f"ğŸ” [Scout] æœç´¢å…³é”®è¯: {enhanced_query[:150]}...")
            print(f"ğŸ“‹ [Scout] èšç„¦: å¯¿é™©ã€å¥åº·é™©ã€æ„å¤–é™©å…·ä½“æ¡ˆä¾‹ï¼ˆæ’é™¤è´¢äº§ä¿é™©ï¼‰")
            
            response = self.client.search(
                query=enhanced_query,
                search_depth="advanced",  # æ·±åº¦æœç´¢æ¨¡å¼
                max_results=max_results,
                include_domains=None,  # ä¸é™åˆ¶åŸŸå
                include_answer=True,  # åŒ…å«ç­”æ¡ˆæ‘˜è¦
                include_raw_content=False,  # ä¸åŒ…å«åŸå§‹HTMLå†…å®¹
            )
            
            results = []
            for item in response.get('results', []):
                url = item.get('url', '')
                title = item.get('title', '').lower()
                content = item.get('content', '').lower()
                
                # è¿‡æ»¤æ¡ä»¶ï¼šæ’é™¤é€šç”¨æ–‡ç« å’Œè´¢äº§ä¿é™©
                should_exclude = False
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é€šç”¨æ–‡ç« ï¼ˆæ ‡é¢˜æˆ–å†…å®¹ä¸­åŒ…å«è¿™äº›è¯ï¼‰
                generic_keywords = [
                    'market report',
                    'market size',
                    'industry outlook',
                    'global market',
                    'forecast',
                    'trends',
                    'analysis report',
                    'research report'
                ]
                
                for keyword in generic_keywords:
                    if keyword in title or keyword in content:
                        should_exclude = True
                        break
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è´¢äº§ä¿é™©å…³é”®è¯ï¼ˆå¦‚æœåŒ…å«åˆ™æ’é™¤ï¼‰
                for exclude_keyword in self.exclude_keywords:
                    if exclude_keyword in title or exclude_keyword in content:
                        should_exclude = True
                        break
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å…·ä½“æ¡ˆä¾‹å…³é”®è¯ï¼ˆå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªï¼‰
                has_case_keyword = False
                for case_keyword in self.case_specific_keywords:
                    if case_keyword in title or case_keyword in content:
                        has_case_keyword = True
                        break
                
                # å¦‚æœæ»¡è¶³æ¡ä»¶ï¼Œæ·»åŠ åˆ°ç»“æœ
                if not should_exclude and has_case_keyword:
                    results.append({
                        'url': url,
                        'title': item.get('title', ''),
                        'content': item.get('content', ''),
                        'score': item.get('score', 0)
                    })
            
            # æŒ‰è´¨é‡åˆ†æ•°æ’åºï¼ˆä»é«˜åˆ°ä½ï¼‰
            results.sort(key=lambda x: x.get('score', 0), reverse=True)
            
            print(f"âœ… [Scout] æœç´¢åˆ° {len(results)} ä¸ªç¬¦åˆæ¡ä»¶çš„å…·ä½“æ¡ˆä¾‹ï¼ˆå·²æŒ‰è´¨é‡æ’åºï¼‰")
            
            if len(results) == 0:
                print("âš ï¸ [Scout] æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¡ˆä¾‹ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æœç´¢ç­–ç•¥")
            
            return results
            
        except Exception as e:
            print(f"âŒ [Scout] æœç´¢å¤±è´¥: {str(e)}")
            return []


# ==================== Agent 2: The Scraper (æŠ“å–å‘˜) ====================

class ScraperAgent:
    """
    æŠ“å–å‘˜ Agentï¼šè´Ÿè´£æŠ“å–ç½‘é¡µå…¨æ–‡å†…å®¹
    ä½¿ç”¨ Jina Reader API è·å–é«˜è´¨é‡å…¨æ–‡å†…å®¹
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or JINA_API_KEY
        self.base_url = "https://r.jina.ai"
    
    def fetch_full_content(self, url: str, top_n: int = 3) -> Optional[Dict]:
        """
        ä½¿ç”¨ Jina Reader æŠ“å–ç½‘é¡µå…¨æ–‡å†…å®¹
        
        å‚æ•°:
            url: ç›®æ ‡ç½‘é¡µ URL
            top_n: åªå¤„ç†å‰ N ä¸ªé«˜è´¨é‡é“¾æ¥ï¼ˆé»˜è®¤3ï¼‰
        
        è¿”å›:
            åŒ…å«å…¨æ–‡å†…å®¹çš„å­—å…¸ï¼Œæˆ– Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        if not self.api_key:
            print(f"âš ï¸ [Scraper] Jina API Key æœªè®¾ç½®ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return None
        
        try:
            # Jina Reader API è°ƒç”¨
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "X-Return-Format": "text"  # è¿”å›çº¯æ–‡æœ¬æ ¼å¼
            }
            
            print(f"ğŸ“¥ [Scraper] æ­£åœ¨æŠ“å–å…¨æ–‡: {url[:80]}...")
            
            response = requests.get(
                f"{self.base_url}/{url}",
                headers=headers,
                timeout=30  # 30ç§’è¶…æ—¶
            )
            
            if response.status_code == 200:
                full_content = response.text
                print(f"âœ… [Scraper] æˆåŠŸæŠ“å–å…¨æ–‡ ({len(full_content)} å­—ç¬¦)")
                return {
                    'url': url,
                    'full_content': full_content,
                    'content_length': len(full_content)
                }
            else:
                print(f"âš ï¸ [Scraper] Jina Reader è¿”å›çŠ¶æ€ç  {response.status_code}")
                # å¦‚æœ Jina å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ requests ç›´æ¥è·å–ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                return self._fallback_fetch(url)
                
        except requests.exceptions.Timeout:
            print(f"âŒ [Scraper] è¯·æ±‚è¶…æ—¶: {url}")
            return None
        except Exception as e:
            print(f"âŒ [Scraper] æŠ“å–å¤±è´¥: {str(e)}")
            # å¤‡ç”¨æ–¹æ¡ˆ
            return self._fallback_fetch(url)
    
    def _fallback_fetch(self, url: str) -> Optional[Dict]:
        """
        å¤‡ç”¨æŠ“å–æ–¹æ¡ˆï¼šä½¿ç”¨ requests ç›´æ¥è·å–ï¼ˆå¦‚æœ Jina ä¸å¯ç”¨ï¼‰
        
        å‚æ•°:
            url: ç›®æ ‡ç½‘é¡µ URL
        
        è¿”å›:
            åŒ…å«å†…å®¹çš„å­—å…¸ï¼Œæˆ– None
        """
        try:
            print(f"ğŸ“¥ [Scraper] ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æŠ“å–: {url[:80]}...")
            response = requests.get(url, timeout=30, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5'
            }, allow_redirects=True)
            
            if response.status_code == 200:
                # ç®€å•çš„æ–‡æœ¬æå–ï¼ˆå»é™¤ HTML æ ‡ç­¾ï¼‰
                content = response.text
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ–‡æœ¬å†…å®¹ï¼ˆç®€å•æ–¹æ³•ï¼‰
                import re
                # ç§»é™¤ script å’Œ style æ ‡ç­¾
                content = re.sub(r'<script[^>]*>.*?</script>', '', content, flags=re.DOTALL | re.IGNORECASE)
                content = re.sub(r'<style[^>]*>.*?</style>', '', content, flags=re.DOTALL | re.IGNORECASE)
                # æå–å¯è§æ–‡æœ¬
                text_content = re.sub(r'<[^>]+>', ' ', content)
                # æ¸…ç†å¤šä½™ç©ºç™½
                text_content = ' '.join(text_content.split())
                
                if len(text_content) > 500:  # ç¡®ä¿æœ‰è¶³å¤Ÿå†…å®¹
                    print(f"âœ… [Scraper] å¤‡ç”¨æ–¹æ³•æˆåŠŸ ({len(text_content)} å­—ç¬¦)")
                    return {
                        'url': url,
                        'full_content': text_content,
                        'content_length': len(text_content),
                        'method': 'fallback'
                    }
                else:
                    print(f"âš ï¸ [Scraper] å¤‡ç”¨æ–¹æ³•æå–å†…å®¹è¿‡å°‘ ({len(text_content)} å­—ç¬¦)")
                    return None
            else:
                print(f"âš ï¸ [Scraper] HTTP çŠ¶æ€ç : {response.status_code}")
                return None
        except requests.exceptions.RequestException as e:
            print(f"âŒ [Scraper] å¤‡ç”¨æ–¹æ³•è¯·æ±‚å¤±è´¥: {str(e)}")
            return None
        except Exception as e:
            print(f"âŒ [Scraper] å¤‡ç”¨æ–¹æ³•å¤„ç†å¤±è´¥: {str(e)}")
            return None


# ==================== Agent 3: The Analyst (åˆ†æå¸ˆ) ====================

class AnalystAgent:
    """
    åˆ†æå¸ˆ Agentï¼šè´Ÿè´£æ·±åº¦åˆ†ææ¡ˆä¾‹ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯
    ä½¿ç”¨ Gemini 1.5 Pro è¿›è¡Œæ·±åº¦åˆ†æ
    """
    
    def __init__(self, gemini_api_key: str):
        genai.configure(api_key=gemini_api_key)
        self.model = None
        self._initialize_model()
    
    def _initialize_model(self):
        """åˆå§‹åŒ– Gemini æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨ Proï¼‰"""
        models_to_try = [
            'models/gemini-1.5-pro',  # ä¼˜å…ˆä½¿ç”¨ Pro
            'models/gemini-2.5-flash',
            'models/gemini-2.0-flash',
            'models/gemini-flash-latest'
        ]
        
        for model_name in models_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                # ç®€å•æµ‹è¯•
                model.generate_content("test")
                self.model = model
                print(f"âœ… [Analyst] ä½¿ç”¨ Gemini æ¨¡å‹: {model_name}")
                return
            except Exception:
                continue
        
        # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        print(f"âš ï¸ [Analyst] ä½¿ç”¨é»˜è®¤ Gemini æ¨¡å‹")
        self.model = genai.GenerativeModel('models/gemini-1.5-pro')
    
    def analyze(self, url: str, title: str, full_content: str) -> Optional[Dict]:
        """
        æ·±åº¦åˆ†ææ¡ˆä¾‹ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯
        
        å‚æ•°:
            url: åŸå§‹é“¾æ¥
            title: æ ‡é¢˜
            full_content: å…¨æ–‡å†…å®¹
        
        è¿”å›:
            ç»“æ„åŒ–æ¡ˆä¾‹æ•°æ®å­—å…¸ï¼Œæˆ– Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        prompt = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ä¿é™©åæ¬ºè¯ˆä¸“å®¶å’Œæ³•åŠ¡åˆ†æå¸ˆã€‚è¯·ä»ä»¥ä¸‹ç½‘é¡µå…¨æ–‡å†…å®¹ä¸­ï¼Œæ·±åº¦åˆ†æä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹ï¼Œå¹¶æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚

ã€ç½‘é¡µä¿¡æ¯ã€‘
æ ‡é¢˜: {title}
é“¾æ¥: {url}

ã€å…¨æ–‡å†…å®¹ã€‘
{full_content[:50000]}  # é™åˆ¶é•¿åº¦é¿å…è¶…å‡º token é™åˆ¶

ã€åˆ†æè¦æ±‚ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¿›è¡Œæ·±åº¦åˆ†æï¼š

1. **Time (æ—¶é—´)**: äº‹ä»¶å‘ç”Ÿæˆ–åˆ¤å†³çš„å…·ä½“æ—¶é—´ï¼ˆæ ¼å¼ï¼šYYYY-MM-DD æˆ– YYYYå¹´MMæœˆDDæ—¥ï¼‰
   - å¦‚æœæ–‡ä¸­æ²¡æœ‰æ˜ç¡®æ—¶é—´ï¼Œå¡«å†™"æœªçŸ¥"

2. **Region (åœ°åŒº)**: å›½å®¶åŠåŸå¸‚
   - ä¾‹å¦‚ï¼šç¾å›½çº½çº¦ã€ä¸­å›½ä¸Šæµ·ã€è‹±å›½ä¼¦æ•¦

3. **Characters (äººç‰©/å®ä½“)**: æ¶‰æ¡ˆäººèº«ä»½ã€ä¿é™©å…¬å¸ã€ä¸­ä»‹æˆ–åŒ»ç–—æœºæ„
   - ç”¨é€—å·åˆ†éš”å¤šä¸ªå®ä½“
   - å¦‚æœæœªæåŠï¼Œå¡«å†™"æœªçŸ¥"

4. **Event (äº‹ä»¶)**: æ¬ºè¯ˆç±»å‹æ¦‚æ‹¬
   - ä¾‹å¦‚ï¼šè½¦é™©éª—ä¿ã€åŒ»ç–—ä¿é™©æ¬ºè¯ˆã€æ„å¤–é™©è™šå‡ç†èµ”ã€æ—…è¡Œä¿é™©æ¬ºè¯ˆ

5. **Process (ç»è¿‡)**: ã€é‡ç‚¹å­—æ®µã€‘è¯¦ç»†çš„ä½œæ¡ˆæ‰‹æ³•ã€é€ƒé¿åˆå®¡çš„è¿‡ç¨‹ã€ä»¥åŠè¢«å‘ç°çš„ç ´ç»½ç»†èŠ‚
   - **å¿…é¡»è¯¦ç»†æè¿°ä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢ï¼š**
     a) **ä½œæ¡ˆæ‰‹æ³•**ï¼šä»–ä»¬å¦‚ä½•å®æ–½æ¬ºè¯ˆï¼ˆå…·ä½“æ­¥éª¤ã€æ‰‹æ®µã€ä¼ªé€ çš„ææ–™ç­‰ï¼‰
     b) **é€ƒé¿åˆå®¡**ï¼šä»–ä»¬å¦‚ä½•é€šè¿‡ä¿é™©å…¬å¸çš„åˆæ­¥å®¡æ ¸ï¼ˆåˆ©ç”¨äº†å“ªäº›æ¼æ´ã€å¦‚ä½•æ©ç›–è¯æ®ç­‰ï¼‰
     c) **ç ´ç»½ç»†èŠ‚**ï¼šæœ€ç»ˆå¦‚ä½•è¢«å‘ç°ï¼ˆè°ƒæŸ¥çº¿ç´¢ã€æŠ€æœ¯æ‰‹æ®µã€å¼‚å¸¸è¡Œä¸ºã€è¯æ®é“¾ç­‰ï¼‰
   - **å¦‚æœæ–‡ä¸­æ²¡æœ‰æåŠç ´ç»½ç»†èŠ‚ï¼Œå¿…é¡»åœ¨ Process å­—æ®µä¸­æ˜ç¡®æ³¨æ˜ï¼š"æ–‡ä¸­æœªæåŠå…·ä½“çš„ç ´ç»½ç»†èŠ‚æˆ–è°ƒæŸ¥å‘ç°è¿‡ç¨‹ï¼Œä¿¡æ¯ç¼ºå¤±"**
   - æ­¤å­—æ®µå¿…é¡»è‡³å°‘ 300 å­—ä»¥ä¸Šï¼Œè¶Šè¯¦ç»†è¶Šå¥½

6. **Result (ç»“æœ)**: åˆ¤å†³ç»“æœã€ç½šé‡‘æˆ–æ³•å¾‹åˆ¶è£
   - åŒ…æ‹¬ï¼šåˆ‘æœŸã€ç½šæ¬¾é‡‘é¢ã€æ°‘äº‹èµ”å¿ã€è¡Œä¸šç¦å…¥ç­‰
   - å¦‚æœæ¡ˆä»¶ä»åœ¨å®¡ç†ä¸­ï¼Œæ³¨æ˜"å®¡ç†ä¸­"
   - å¦‚æœæœªæåŠç»“æœï¼Œå¡«å†™"æœªçŸ¥"

ã€è¾“å‡ºè¦æ±‚ã€‘
- å¿…é¡»ä»¥çº¯ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown æ ‡è®°æˆ–é¢å¤–è¯´æ˜
- æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å¡«å†™ï¼Œå¦‚æœä¿¡æ¯ç¼ºå¤±è¯·å¡«å†™"æœªçŸ¥"æˆ–"å¾…è¡¥å……"
- Process å­—æ®µå¿…é¡»è¯¦ç»†ï¼Œè‡³å°‘ 300 å­—ä»¥ä¸Š
- å¦‚æœæ–‡ä¸­ç¡®å®æ²¡æœ‰æåŠç ´ç»½ï¼Œå¿…é¡»åœ¨ Process ä¸­æ˜ç¡®è¯´æ˜
- å­—æ®µåä½¿ç”¨è‹±æ–‡ï¼ˆTime, Region, Characters, Event, Process, Resultï¼‰

ã€JSON æ ¼å¼ç¤ºä¾‹ã€‘
{{
    "Time": "2025-01-15",
    "Region": "ç¾å›½çº½çº¦",
    "Characters": "John Smith, ABCä¿é™©å…¬å¸, XYZåŒ»ç–—ä¸­å¿ƒ",
    "Event": "åŒ»ç–—ä¿é™©æ¬ºè¯ˆ",
    "Process": "è¯¦ç»†æè¿°ä½œæ¡ˆç»è¿‡...ï¼ˆå¿…é¡»åŒ…å«ä½œæ¡ˆæ‰‹æ³•ã€é€ƒé¿åˆå®¡ã€ç ´ç»½ç»†èŠ‚ä¸‰ä¸ªéƒ¨åˆ†ï¼‰",
    "Result": "è¢«åˆ¤æœ‰æœŸå¾’åˆ‘5å¹´ï¼Œç½šæ¬¾50ä¸‡ç¾å…ƒ"
}}

ç°åœ¨è¯·å¼€å§‹åˆ†æï¼š
"""

        try:
            print(f"ğŸ§  [Analyst] æ­£åœ¨æ·±åº¦åˆ†ææ¡ˆä¾‹...")
            
            response = self.model.generate_content(prompt)
            text = response.text.strip()
            
            # æ¸…ç†å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®°
            if text.startswith("```json"):
                text = text[7:]
            if text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()
            
            # æ¸…ç†æ§åˆ¶å­—ç¬¦ï¼ˆå¯èƒ½å¯¼è‡´ JSON è§£æå¤±è´¥ï¼‰
            import re
            text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)  # ç§»é™¤æ§åˆ¶å­—ç¬¦
            
            # è§£æ JSON
            case_data = json.loads(text)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['Time', 'Region', 'Characters', 'Event', 'Process', 'Result']
            for field in required_fields:
                if field not in case_data:
                    case_data[field] = "æœªçŸ¥"
            
            # éªŒè¯ Process å­—æ®µé•¿åº¦
            if len(case_data.get('Process', '')) < 200:
                case_data['Process'] += " [æ³¨ï¼šæ–‡ä¸­ä¿¡æ¯æœ‰é™ï¼Œç ´ç»½ç»†èŠ‚å¯èƒ½ä¸å®Œæ•´]"
            
            # æ·»åŠ å…ƒæ•°æ®
            case_data['Source_URL'] = url
            case_data['Created_at'] = datetime.now().isoformat()
            
            print(f"âœ… [Analyst] æˆåŠŸæå–æ¡ˆä¾‹: {case_data.get('Event', 'æœªçŸ¥äº‹ä»¶')}")
            return case_data
            
        except json.JSONDecodeError as e:
            print(f"âŒ [Analyst] JSON è§£æå¤±è´¥: {str(e)}")
            print(f"åŸå§‹å“åº”å‰500å­—ç¬¦: {text[:500] if 'text' in locals() else 'N/A'}")
            return None
        except Exception as e:
            print(f"âŒ [Analyst] åˆ†æå¤±è´¥: {str(e)}")
            return None


# ==================== Agent 4: The Critic (è´¨æ£€å‘˜) ====================

class CriticAgent:
    """
    è´¨æ£€å‘˜ Agentï¼šè´Ÿè´£éªŒè¯æå–ç»“æœçš„è´¨é‡
    ä½¿ç”¨ GPT-4o-mini å¯¹æ¯”åŸæ–‡å’Œæå–ç»“æœï¼Œç¡®ä¿æ²¡æœ‰è™šæ„æˆåˆ†
    """
    
    def __init__(self, openai_api_key: Optional[str] = None):
        if openai_api_key:
            self.client = OpenAI(api_key=openai_api_key)
        else:
            self.client = openai_client
        self.model_name = "gpt-4o-mini"
    
    def validate(self, extracted_data: Dict, original_content: str, url: str) -> Tuple[bool, Dict]:
        """
        éªŒè¯æå–ç»“æœçš„è´¨é‡ï¼Œç¡®ä¿æ²¡æœ‰è™šæ„æˆåˆ†
        
        å‚æ•°:
            extracted_data: Analyst æå–çš„ç»“æ„åŒ–æ•°æ®
            original_content: åŸå§‹ç½‘é¡µå†…å®¹
            url: åŸæ–‡é“¾æ¥
        
        è¿”å›:
            (is_valid, validation_result) å…ƒç»„
            is_valid: True è¡¨ç¤ºé€šè¿‡éªŒè¯ï¼ŒFalse è¡¨ç¤ºéœ€è¦ä¿®æ­£
            validation_result: åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        if not self.client:
            print(f"âš ï¸ [Critic] OpenAI API Key æœªè®¾ç½®ï¼Œè·³è¿‡è´¨æ£€")
            return True, {'skipped': True, 'reason': 'API Key æœªè®¾ç½®'}
        
        try:
            print(f"ğŸ” [Critic] æ­£åœ¨éªŒè¯æå–ç»“æœè´¨é‡...")
            
            # æ„å»ºéªŒè¯ prompt
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸¥æ ¼çš„è´¨é‡æ£€æŸ¥å‘˜ã€‚è¯·å¯¹æ¯”ä»¥ä¸‹"æå–ç»“æœ"å’Œ"åŸæ–‡å†…å®¹"ï¼ŒéªŒè¯æå–ç»“æœæ˜¯å¦å‡†ç¡®ï¼Œæ˜¯å¦å­˜åœ¨è™šæ„æˆåˆ†ã€‚

ã€åŸæ–‡é“¾æ¥ã€‘
{url}

ã€æå–ç»“æœã€‘
{json.dumps(extracted_data, ensure_ascii=False, indent=2)}

ã€åŸæ–‡å†…å®¹ï¼ˆæ‘˜è¦ï¼Œå‰10000å­—ç¬¦ï¼‰ã€‘
{original_content[:10000]}

ã€éªŒè¯è¦æ±‚ã€‘
è¯·æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. **å‡†ç¡®æ€§**ï¼šæå–çš„ä¿¡æ¯æ˜¯å¦åœ¨åŸæ–‡ä¸­æœ‰ä¾æ®ï¼Ÿ
2. **å®Œæ•´æ€§**ï¼šå…³é”®ä¿¡æ¯ï¼ˆæ—¶é—´ã€åœ°åŒºã€äººç‰©ã€äº‹ä»¶ã€ç»è¿‡ã€ç»“æœï¼‰æ˜¯å¦éƒ½æœ‰ä¾æ®ï¼Ÿ
3. **è™šæ„æ£€æµ‹**ï¼šæ˜¯å¦å­˜åœ¨åŸæ–‡ä¸­æ²¡æœ‰æåˆ°ï¼Œä½†æå–ç»“æœä¸­å‡ºç°çš„è™šæ„å†…å®¹ï¼Ÿ
4. **ç ´ç»½åˆ†æ**ï¼šProcess å­—æ®µä¸­çš„"ç ´ç»½ç»†èŠ‚"æ˜¯å¦åœ¨åŸæ–‡ä¸­æœ‰æ˜ç¡®ä¾æ®ï¼Ÿå¦‚æœæ²¡æœ‰ä¾æ®ï¼Œæ˜¯å¦å·²æ³¨æ˜"ä¿¡æ¯ç¼ºå¤±"ï¼Ÿ

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºéªŒè¯ç»“æœï¼š
{{
    "is_valid": true/false,  // æ˜¯å¦é€šè¿‡éªŒè¯
    "issues": ["é—®é¢˜1", "é—®é¢˜2", ...],  // å‘ç°çš„é—®é¢˜åˆ—è¡¨ï¼ˆå¦‚æœæ²¡æœ‰é—®é¢˜åˆ™ä¸ºç©ºæ•°ç»„ï¼‰
    "confidence": 0.0-1.0,  // å¯¹æå–ç»“æœçš„ç½®ä¿¡åº¦
    "suggestions": ["å»ºè®®1", "å»ºè®®2", ...]  // æ”¹è¿›å»ºè®®ï¼ˆå¦‚æœæœ‰ï¼‰
}}

è¯·å¼€å§‹éªŒè¯ï¼š
"""

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸¥æ ¼çš„è´¨é‡æ£€æŸ¥å‘˜ï¼Œä¸“é—¨éªŒè¯AIæå–ä¿¡æ¯çš„å‡†ç¡®æ€§ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # ä½æ¸©åº¦ï¼Œæ›´ä¸¥è°¨
                max_tokens=1000
            )
            
            result_text = response.choices[0].message.content.strip() if response.choices else ""
            
            if not result_text:
                print(f"âš ï¸ [Critic] æœªè·å–åˆ°æœ‰æ•ˆå“åº”")
                return True, {'skipped': True, 'reason': 'Empty response'}
            
            # æ¸…ç†å¯èƒ½çš„ Markdown æ ‡è®°
            if result_text.startswith("```json"):
                result_text = result_text[7:]
            if result_text.startswith("```"):
                result_text = result_text[3:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
            result_text = result_text.strip()
            
            # è§£æéªŒè¯ç»“æœ
            validation_result = json.loads(result_text)
            
            is_valid = validation_result.get('is_valid', False)
            issues = validation_result.get('issues', [])
            confidence = validation_result.get('confidence', 0.5)
            
            if is_valid:
                print(f"âœ… [Critic] éªŒè¯é€šè¿‡ï¼ˆç½®ä¿¡åº¦: {confidence:.2f}ï¼‰")
            else:
                print(f"âš ï¸ [Critic] éªŒè¯æœªé€šè¿‡ï¼Œå‘ç°é—®é¢˜: {len(issues)} ä¸ª")
                for issue in issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                    print(f"   - {issue}")
            
            return is_valid, validation_result
            
        except json.JSONDecodeError as e:
            print(f"âš ï¸ [Critic] JSON è§£æå¤±è´¥: {str(e)}")
            # JSON è§£æå¤±è´¥æ—¶ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­åˆ¤æ–­
            if "valid" in result_text.lower() or "é€šè¿‡" in result_text:
                return True, {'parsed_from_text': True}
            return False, {'parse_error': str(e)}
        except Exception as e:
            print(f"âš ï¸ [Critic] éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
            # å‡ºé”™æ—¶é»˜è®¤é€šè¿‡ï¼Œä¸é˜»å¡æµç¨‹
            return True, {'error': str(e)}


# ==================== æ•°æ®åº“æ“ä½œ ====================

def check_duplicate(url: str) -> bool:
    """æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨è¯¥ URLï¼ˆå»é‡ï¼‰"""
    if not supabase:
        return False
    try:
        result = supabase.table('fraud_cases').select('id').eq('source_url', url).execute()
        return len(result.data) > 0
    except Exception as e:
        print(f"âš ï¸ æŸ¥é‡å¤±è´¥: {str(e)}")
        return False


def save_to_supabase(case_data: Dict, validation_result: Optional[Dict] = None) -> bool:
    """
    å°†æ¡ˆä¾‹æ•°æ®ä¿å­˜åˆ° Supabase æ•°æ®åº“
    
    å‚æ•°:
        case_data: åŒ…å«æ‰€æœ‰å­—æ®µçš„æ¡ˆä¾‹å­—å…¸
        validation_result: Critic çš„éªŒè¯ç»“æœï¼ˆå¯é€‰ï¼‰
    
    è¿”å›:
        True è¡¨ç¤ºä¿å­˜æˆåŠŸï¼ŒFalse è¡¨ç¤ºä¿å­˜å¤±è´¥
    """
    if not supabase:
        print(f"âŒ Supabase æœªåˆå§‹åŒ–")
        return False
    
    try:
        # å‡†å¤‡æ’å…¥æ•°æ®
        insert_data = {
            'time': case_data.get('Time', 'æœªçŸ¥'),
            'region': case_data.get('Region', 'æœªçŸ¥'),
            'characters': case_data.get('Characters', 'æœªçŸ¥'),
            'event': case_data.get('Event', 'æœªçŸ¥'),
            'process': case_data.get('Process', 'æœªçŸ¥'),
            'result': case_data.get('Result', 'æœªçŸ¥'),
            'source_url': case_data.get('Source_URL', ''),
            'created_at': case_data.get('Created_at', datetime.now().isoformat())
        }
        
        # å¦‚æœæœ‰éªŒè¯ç»“æœï¼Œå¯ä»¥åœ¨æ³¨é‡Šä¸­è®°å½•ï¼ˆå¯é€‰ï¼‰
        if validation_result and not validation_result.get('skipped'):
            # å¯ä»¥åœ¨ process å­—æ®µæœ«å°¾æ·»åŠ éªŒè¯æ ‡è®°
            confidence = validation_result.get('confidence', 0.5)
            if confidence < 0.7:
                insert_data['process'] += f" [éªŒè¯ç½®ä¿¡åº¦: {confidence:.2f}]"
        
        # æ’å…¥æ•°æ®åº“
        result = supabase.table('fraud_cases').insert(insert_data).execute()
        
        if result.data:
            print(f"âœ… æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“: {insert_data['event']}")
            return True
        else:
            print(f"âš ï¸ ä¿å­˜å¤±è´¥: æ— è¿”å›æ•°æ®")
            return False
            
    except Exception as e:
        print(f"âŒ ä¿å­˜åˆ° Supabase å¤±è´¥: {str(e)}")
        return False


# ==================== ä¸»æµç¨‹ ====================

def main():
    """
    ä¸»å‡½æ•°ï¼šå¤š Agent åä½œæµç¨‹
    1. The Scout: æœç´¢é«˜è´¨é‡æ¡ˆä¾‹
    2. The Scraper: æŠ“å–å‰3ä¸ªé“¾æ¥çš„å…¨æ–‡
    3. The Analyst: æ·±åº¦åˆ†ææå–ä¿¡æ¯
    4. The Critic: è´¨é‡æ£€æŸ¥éªŒè¯
    """
    print("=" * 70)
    print("ğŸš€ GIFIA v2.0 - å…¨çƒä¿é™©æ¬ºè¯ˆæƒ…æŠ¥æŠ“å–ï¼ˆå¤š Agent åä½œæ¨¡å¼ï¼‰")
    print(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # éªŒè¯å¿…è¦çš„ API Key
    if not all([TAVILY_API_KEY, GEMINI_API_KEY, SUPABASE_URL, SUPABASE_KEY]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ API Key æˆ–é…ç½®")
        print("è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡: TAVILY_API_KEY, GEMINI_API_KEY, SUPABASE_URL, SUPABASE_KEY")
        return
    
    if not JINA_API_KEY:
        print("âš ï¸ è­¦å‘Š: JINA_API_KEY æœªè®¾ç½®ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æŠ“å–æ–¹æ³•")
    if not OPENAI_API_KEY:
        print("âš ï¸ è­¦å‘Š: OPENAI_API_KEY æœªè®¾ç½®ï¼Œå°†è·³è¿‡è´¨é‡æ£€æŸ¥")
    
    # ========== æ­¥éª¤ 1: The Scout ==========
    print("\n" + "=" * 70)
    print("ğŸ“¡ æ­¥éª¤ 1: The Scout - æœç´¢é«˜è´¨é‡å…·ä½“æ¡ˆä¾‹")
    print("=" * 70)
    print("ğŸ¯ èšç„¦: å¯¿é™©ã€å¥åº·é™©ã€æ„å¤–é™©å…·ä½“æ¬ºè¯ˆæ¡ˆä¾‹ï¼ˆæ’é™¤è´¢äº§ä¿é™©å’Œé€šç”¨æ–‡ç« ï¼‰")
    print("=" * 70)
    
    scout = ScoutAgent(tavily_client)
    search_results = scout.search(
        base_query=None,  # ä¸å†ä½¿ç”¨åŸºç¡€æŸ¥è¯¢
        max_results=15  # æœç´¢æ›´å¤šä»¥ç­›é€‰å·®å¼‚æ€§
    )
    
    if not search_results:
        print("âš ï¸ æœªæœç´¢åˆ°ä»»ä½•ç¬¦åˆæ¡ä»¶çš„æ¡ˆä¾‹ï¼Œç¨‹åºé€€å‡º")
        return
    
    # ========== ç­›é€‰ç¡®ä¿æ¡ˆä¾‹å·®å¼‚æ€§ ==========
    print(f"\nğŸ” [Scout] ç­›é€‰ç¡®ä¿æ¡ˆä¾‹å·®å¼‚æ€§...")
    
    # ä»æœç´¢ç»“æœä¸­é€‰æ‹©å…·æœ‰å·®å¼‚æ€§çš„æ¡ˆä¾‹
    diverse_links = []
    seen_types = set()  # è®°å½•å·²é€‰æ‹©çš„ä¿é™©ç±»å‹
    seen_keywords = set()  # è®°å½•å·²é€‰æ‹©çš„å…³é”®ç‰¹å¾
    
    for result in search_results:
        title = result['title'].lower()
        content = result.get('content', '').lower()
        
        # è¯†åˆ«æ¡ˆä¾‹çš„ä¿é™©ç±»å‹
        case_type = None
        if 'life insurance' in title or 'life insurance' in content or 'å¯¿é™©' in content:
            case_type = 'life'
        elif 'health insurance' in title or 'health insurance' in content or 'medical insurance' in title or 'health insurance' in content or 'å¥åº·é™©' in content or 'åŒ»ç–—ä¿é™©' in content:
            case_type = 'health'
        elif 'accident insurance' in title or 'accident insurance' in content or 'disability insurance' in title or 'æ„å¤–é™©' in content:
            case_type = 'accident'
        
        # è¯†åˆ«æ¡ˆä¾‹çš„å…³é”®ç‰¹å¾ï¼ˆç”¨äºå·®å¼‚åŒ–ï¼‰
        case_keyword = None
        for keyword in ['fraud scheme', 'fraud ring', 'medical fraud', 'death benefit', 'disability claim', 'accident claim']:
            if keyword in title or keyword in content:
                case_keyword = keyword
                break
        
        # ç¡®ä¿æ¡ˆä¾‹ç±»å‹å’Œç‰¹å¾çš„å·®å¼‚æ€§
        is_diverse = True
        
        # å¦‚æœå·²ç»æœ‰ç›¸åŒç±»å‹çš„æ¡ˆä¾‹ï¼Œä¼˜å…ˆé€‰æ‹©ä¸åŒç±»å‹
        if case_type and case_type in seen_types:
            # æ£€æŸ¥æ˜¯å¦æœ‰å…³é”®è¯å·®å¼‚
            if case_keyword and case_keyword not in seen_keywords:
                is_diverse = True  # è™½ç„¶ç±»å‹ç›¸åŒï¼Œä½†ç‰¹å¾ä¸åŒï¼Œå¯ä»¥æ¥å—
            else:
                is_diverse = False  # ç±»å‹å’Œç‰¹å¾éƒ½ç›¸åŒï¼Œè·³è¿‡
        
        # å¦‚æœæ¡ˆä¾‹ç±»å‹ä¸æ˜ç¡®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿå·®å¼‚
        if not case_type:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„ä¿é™©ç±»å‹ï¼Œæ£€æŸ¥æ ‡é¢˜å’Œå†…å®¹çš„ç‹¬ç‰¹æ€§
            title_words = set(title.split()[:10])  # å–å‰10ä¸ªè¯
            for existing in diverse_links:
                existing_title_words = set(existing['title'].lower().split()[:10])
                # å¦‚æœæ ‡é¢˜ç›¸ä¼¼åº¦å¤ªé«˜ï¼ˆè¶…è¿‡50%ç›¸åŒè¯ï¼‰ï¼Œè·³è¿‡
                if len(title_words & existing_title_words) / max(len(title_words), 1) > 0.5:
                    is_diverse = False
                    break
        
        if is_diverse:
            diverse_links.append(result)
            if case_type:
                seen_types.add(case_type)
            if case_keyword:
                seen_keywords.add(case_keyword)
            
            # é€‰æ‹©æœ€å¤š5ä¸ªå…·æœ‰å·®å¼‚æ€§çš„æ¡ˆä¾‹ï¼ˆä½†ä¼˜å…ˆé€‰æ‹©å‰3ä¸ªï¼‰
            if len(diverse_links) >= 5:
                break
    
    # å¦‚æœç­›é€‰åæ¡ˆä¾‹ä¸è¶³ï¼Œè‡³å°‘é€‰æ‹©å‰3ä¸ªï¼ˆå³ä½¿ç›¸ä¼¼åº¦è¾ƒé«˜ï¼‰
    if len(diverse_links) < 3:
        print(f"âš ï¸ [Scout] å·®å¼‚æ€§ç­›é€‰ååªæœ‰ {len(diverse_links)} ä¸ªæ¡ˆä¾‹ï¼Œè¡¥å……è‡³3ä¸ª...")
        # ä»å‰©ä½™ç»“æœä¸­è¡¥å……
        for result in search_results:
            if result not in diverse_links:
                diverse_links.append(result)
                if len(diverse_links) >= 3:
                    break
    
    # é€‰æ‹©å‰3ä¸ªé«˜è´¨é‡ä¸”æœ‰å·®å¼‚æ€§çš„æ¡ˆä¾‹
    top_links = diverse_links[:3]
    
    print(f"\nâœ… Scout å®Œæˆï¼š")
    print(f"   - æœç´¢åˆ° {len(search_results)} ä¸ªç¬¦åˆæ¡ä»¶çš„æ¡ˆä¾‹")
    print(f"   - ç­›é€‰å‡º {len(diverse_links)} ä¸ªæœ‰å·®å¼‚æ€§çš„æ¡ˆä¾‹")
    print(f"   - é€‰æ‹©å‰ {len(top_links)} ä¸ªé«˜è´¨é‡æ¡ˆä¾‹è¿›è¡Œæ·±åº¦åˆ†æ")
    
    # æ˜¾ç¤ºé€‰æ‹©çš„æ¡ˆä¾‹ç±»å‹
    if top_links:
        print(f"\nğŸ“‹ é€‰æ‹©çš„æ¡ˆä¾‹æ¦‚è§ˆï¼š")
        for i, link in enumerate(top_links, 1):
            print(f"   {i}. {link['title'][:60]}...")
    
    # ========== æ­¥éª¤ 2-4: å¯¹æ¯ä¸ªé“¾æ¥è¿›è¡Œ Scraper -> Analyst -> Critic ==========
    print("\n" + "=" * 70)
    print(f"ğŸ”„ æ­¥éª¤ 2-4: å¤„ç† {len(top_links)} ä¸ªé«˜è´¨é‡æ¡ˆä¾‹")
    print("=" * 70)
    
    scraper = ScraperAgent(JINA_API_KEY)
    analyst = AnalystAgent(GEMINI_API_KEY)
    critic = CriticAgent(OPENAI_API_KEY)
    
    saved_count = 0
    skipped_count = 0
    failed_count = 0
    
    for i, search_result in enumerate(top_links, 1):
        url = search_result['url']
        title = search_result['title']
        summary = search_result.get('content', '')
        
        print(f"\n{'='*70}")
        print(f"ğŸ“¦ å¤„ç†æ¡ˆä¾‹ {i}/{len(top_links)}")
        print(f"{'='*70}")
        print(f"ğŸ”— URL: {url[:80]}...")
        print(f"ğŸ“„ æ ‡é¢˜: {title}")
        
        # æ£€æŸ¥æ˜¯å¦é‡å¤
        if check_duplicate(url):
            print(f"â­ï¸  è·³è¿‡: URL å·²å­˜åœ¨ï¼ˆå»é‡ï¼‰")
            skipped_count += 1
            continue
        
        # ========== æ­¥éª¤ 2: The Scraper ==========
        print(f"\nğŸ“¥ [æ­¥éª¤ 2] The Scraper - æŠ“å–å…¨æ–‡å†…å®¹...")
        scraped_data = scraper.fetch_full_content(url)
        
        if not scraped_data:
            print(f"âŒ Scraper å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¡ˆä¾‹")
            failed_count += 1
            # å³ä½¿æŠ“å–å¤±è´¥ï¼Œä¹Ÿå¯ä»¥å°è¯•ç”¨æ‘˜è¦åˆ†æï¼ˆé™çº§å¤„ç†ï¼‰
            if summary:
                print(f"âš ï¸ å°è¯•ä½¿ç”¨æœç´¢æ‘˜è¦è¿›è¡Œåˆ†æ...")
                scraped_data = {
                    'url': url,
                    'full_content': summary,
                    'content_length': len(summary),
                    'method': 'summary_fallback'
                }
            else:
                continue
        
        full_content = scraped_data['full_content']
        print(f"âœ… Scraper å®Œæˆï¼šè·å– {len(full_content)} å­—ç¬¦å†…å®¹")
        
        # ========== æ­¥éª¤ 3: The Analyst ==========
        print(f"\nğŸ§  [æ­¥éª¤ 3] The Analyst - æ·±åº¦åˆ†ææå–ä¿¡æ¯...")
        extracted_data = analyst.analyze(url, title, full_content)
        
        if not extracted_data:
            print(f"âŒ Analyst å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¡ˆä¾‹")
            failed_count += 1
            continue
        
        print(f"âœ… Analyst å®Œæˆï¼šæˆåŠŸæå–ç»“æ„åŒ–ä¿¡æ¯")
        
        # ========== æ­¥éª¤ 4: The Critic ==========
        print(f"\nğŸ” [æ­¥éª¤ 4] The Critic - è´¨é‡æ£€æŸ¥éªŒè¯...")
        is_valid, validation_result = critic.validate(extracted_data, full_content, url)
        
        if not is_valid and not validation_result.get('skipped'):
            issues = validation_result.get('issues', [])
            print(f"âš ï¸ Critic å‘ç°é—®é¢˜ï¼Œä½†ç»§ç»­ä¿å­˜ï¼ˆå¯åœ¨åç»­ç‰ˆæœ¬ä¸­å®ç°è‡ªåŠ¨ä¿®æ­£ï¼‰")
            print(f"   é—®é¢˜æ•°é‡: {len(issues)}")
            # å¯ä»¥é€‰æ‹©ï¼š1) æ‹’ç»ä¿å­˜ 2) æ ‡è®°åä¿å­˜ 3) è‡ªåŠ¨ä¿®æ­£åä¿å­˜
            # å½“å‰ç‰ˆæœ¬é€‰æ‹©æ ‡è®°åä¿å­˜
        
        print(f"âœ… Critic å®Œæˆï¼šéªŒè¯ç»“æœå·²è®°å½•")
        
        # ========== ä¿å­˜åˆ°æ•°æ®åº“ ==========
        print(f"\nğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
        if save_to_supabase(extracted_data, validation_result):
            saved_count += 1
            print(f"âœ… æ¡ˆä¾‹ä¿å­˜æˆåŠŸ")
        else:
            failed_count += 1
            print(f"âŒ ä¿å­˜å¤±è´¥")
        
        # é¿å… API é™æµ
        if i < len(top_links):
            wait_time = 15
            print(f"\nâ³ ç­‰å¾… {wait_time} ç§’ä»¥é¿å… API é™æµ...")
            time.sleep(wait_time)
    
    # ========== è¾“å‡ºç»Ÿè®¡ä¿¡æ¯ ==========
    print("\n" + "=" * 70)
    print("ğŸ“Š æŠ“å–å®Œæˆç»Ÿè®¡")
    print("=" * 70)
    print(f"âœ… æˆåŠŸä¿å­˜: {saved_count} ä¸ªæ¡ˆä¾‹")
    print(f"â­ï¸  è·³è¿‡ï¼ˆé‡å¤ï¼‰: {skipped_count} ä¸ªæ¡ˆä¾‹")
    print(f"âŒ å¤±è´¥: {failed_count} ä¸ªæ¡ˆä¾‹")
    print(f"ğŸ“ˆ æ€»è®¡å¤„ç†: {len(top_links)} ä¸ªé«˜è´¨é‡æ¡ˆä¾‹")
    print(f"ğŸ” Scout æœç´¢: {len(search_results)} ä¸ªç»“æœï¼ˆé€‰æ‹©å‰{len(top_links)}ä¸ªï¼‰")
    print("=" * 70)


if __name__ == "__main__":
    main()
