"""
GIFIA - ç§å­æ¡ˆä¾‹åº“æå–å™¨
ä»æ·±åº¦ç ”ç©¶æŠ¥å‘Šä¸­æå–æ¡ˆä¾‹ï¼Œæ„å»º50ä¸ªæ ¸å¿ƒç§å­æ¡ˆä¾‹åº“
"""

import os
import json
import re
from datetime import datetime
from typing import Dict, List, Optional
from supabase import create_client, Client
import google.generativeai as genai
from tavily import TavilyClient
from openai import OpenAI

# å°è¯•å¯¼å…¥ docx åº“
try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("âš ï¸ python-docx æœªå®‰è£…ï¼Œæ— æ³•è¯»å– Word æ–‡æ¡£")
    print("è¯·è¿è¡Œ: pip install python-docx")

# ==================== ç¯å¢ƒå˜é‡é…ç½® ====================

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
genai.configure(api_key=GEMINI_API_KEY)
tavily_client = TavilyClient(api_key=TAVILY_API_KEY) if TAVILY_API_KEY else None
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None

# ==================== Word æ–‡æ¡£æå– ====================

def extract_text_from_docx(file_path: str) -> str:
    """ä» Word æ–‡æ¡£ä¸­æå–æ–‡æœ¬"""
    if not DOCX_AVAILABLE:
        return ""
    
    try:
        doc = Document(file_path)
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)
        return "\n".join(full_text)
    except Exception as e:
        print(f"âŒ è¯»å– Word æ–‡æ¡£å¤±è´¥ {file_path}: {str(e)}")
        return ""


def extract_cases_from_reports(report_files: List[str]) -> List[Dict]:
    """
    ä»ç ”ç©¶æŠ¥å‘Šä¸­æå–æ¡ˆä¾‹
    
    å‚æ•°:
        report_files: Word æ–‡æ¡£æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    
    è¿”å›:
        æå–çš„æ¡ˆä¾‹åˆ—è¡¨
    """
    all_text = ""
    
    # è¯»å–æ‰€æœ‰æŠ¥å‘Š
    for file_path in report_files:
        if os.path.exists(file_path):
            print(f"ğŸ“„ æ­£åœ¨è¯»å–: {os.path.basename(file_path)}")
            text = extract_text_from_docx(file_path)
            all_text += f"\n\n=== {os.path.basename(file_path)} ===\n\n{text}"
        else:
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    if not all_text:
        print("âŒ æœªèƒ½ä»æŠ¥å‘Šä¸­æå–ä»»ä½•æ–‡æœ¬")
        return []
    
    # ä½¿ç”¨ Gemini æå–æ¡ˆä¾‹
    print(f"\nğŸ§  ä½¿ç”¨ AI ä»æŠ¥å‘Šä¸­æå–æ¡ˆä¾‹...")
    print(f"   æŠ¥å‘Šæ€»é•¿åº¦: {len(all_text)} å­—ç¬¦")
    
    prompt = f"""
ä½ æ˜¯ä¸€ä½å…¨çƒå¯¿é™©ä¸å¥åº·é™©åæ¬ºè¯ˆä¸“å®¶ï¼ˆSIU èµ„æ·±è°ƒæŸ¥å‘˜ï¼‰ã€‚è¯·ä»ä»¥ä¸‹æ·±åº¦ç ”ç©¶æŠ¥å‘Šä¸­æå–æ‰€æœ‰å…·ä½“çš„ä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹ã€‚

ã€ç ”ç©¶æŠ¥å‘Šå†…å®¹ã€‘
{all_text[:100000]}  # é™åˆ¶é•¿åº¦é¿å…è¶…å‡º token é™åˆ¶

ã€æå–ä»»åŠ¡ã€‘
è¯·æå–æŠ¥å‘Šä¸­æåˆ°çš„æ‰€æœ‰å…·ä½“æ¡ˆä¾‹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
- "DMERx 10äº¿ç¾å…ƒæ¡ˆ"
- "æ— é”¡è™¹æ¡¥åŒ»é™¢æ¡ˆ"
- "å°æ¹¾å¹²å†°æˆªè‚¢æ¡ˆ"
- "è‹±å›½åŒ»ç”Ÿ Neil Hopper è‡ªæ®‹æ¡ˆ"
- "æ³°å›½æ‚¬å´–/æ€å¦»éª—ä¿æ¡ˆ"
- "å°åº¦ Star 24 å‡å®éªŒå®¤æ¡ˆ"
- ä»¥åŠå…¶ä»–æ‰€æœ‰å…·ä½“æ¡ˆä¾‹

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ä»¥ JSON æ•°ç»„æ ¼å¼è¾“å‡ºï¼Œæ¯ä¸ªæ¡ˆä¾‹åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
    "case_name": "æ¡ˆä¾‹åç§°",
    "time": "æ—¶é—´ï¼ˆYYYY-MM-DD æˆ– YYYYå¹´MMæœˆDDæ—¥ï¼‰",
    "region": "åœ°åŒºï¼ˆå›½å®¶åŠåŸå¸‚ï¼‰",
    "characters": "æ¶‰æ¡ˆäºº/å®ä½“",
    "line_of_business": "é™©ç§ï¼ˆåŒ»ç–—é™©/é‡ç–¾é™©/å®šæœŸå¯¿é™©ç­‰ï¼‰",
    "fraud_type": "æ¬ºè¯ˆå®šæ€§ï¼ˆFraud/Abuse/Wasteï¼‰",
    "modus_operandi": "èˆå¼Šæ‰‹æ³•ï¼ˆMO - è¯¦è¿°å¦‚ä½•é€ å‡ï¼‰",
    "red_flags": "çº¢æ——æŒ‡æ ‡ï¼ˆé¢„è­¦ä¿¡å·ï¼‰",
    "investigative_tips": "è°ƒæŸ¥çªç ´ç‚¹",
    "underwriting_advice": "é£æ§/æ ¸ä¿å»ºè®®",
    "result": "åˆ¤å†³ç»“æœ",
    "source_reference": "æŠ¥å‘Šä¸­çš„å¼•ç”¨æˆ–é¡µç "
}}

ã€è¦æ±‚ã€‘
- åªæå–å…·ä½“çš„æ¡ˆä¾‹ï¼Œä¸è¦æå–é€šç”¨æè¿°
- å¦‚æœæŸä¸ªå­—æ®µä¿¡æ¯ç¼ºå¤±ï¼Œå¡«å†™"ä¿¡æ¯ç¼ºå¤±"
- è¾“å‡ºçº¯ JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown æ ‡è®°
- å°½å¯èƒ½æå–æ‰€æœ‰æ¡ˆä¾‹

ç°åœ¨è¯·å¼€å§‹æå–ï¼š
"""

    try:
        # ä½¿ç”¨ Gemini æå–ï¼ˆå¸¦ Failoverï¼‰
        text = None
        last_error = None
        
        # å°è¯• Gemini
        try:
            print("   [Gemini] æ­£åœ¨åˆ†ææŠ¥å‘Š...")
            model = genai.GenerativeModel('models/gemini-2.5-flash')
            response = model.generate_content(prompt)
            text = response.text.strip()
        except Exception as e:
            last_error = str(e)
            error_str = str(e).lower()
            if any(k in error_str for k in ["quota", "rate", "429", "exceeded", "limit"]):
                print("   âš ï¸ Gemini é™é¢ï¼Œåˆ‡æ¢è‡³ DeepSeek å¤‡ä»½å¼•æ“...")
            else:
                print(f"   âš ï¸ Gemini å¼‚å¸¸: {str(e)[:100]}ï¼Œåˆ‡æ¢è‡³ DeepSeek...")
        
        # å¦‚æœ Gemini å¤±è´¥ï¼Œå°è¯• DeepSeek
        if not text and DEEPSEEK_API_KEY:
            try:
                print("   [DeepSeek] æ­£åœ¨æ¥ç®¡ä»»åŠ¡...")
                ds_client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")
                completion = ds_client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å…¨çƒå¯¿é™©ä¸å¥åº·é™©åæ¬ºè¯ˆä¸“å®¶ï¼ˆSIU èµ„æ·±è°ƒæŸ¥å‘˜ï¼‰ï¼Œæ“…é•¿ä»é•¿æ–‡ä¸­æå–å…·ä½“æ¡ˆä¾‹ã€‚"},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,
                    max_tokens=4000,
                )
                text = (completion.choices[0].message.content or "").strip()
            except Exception as e2:
                print(f"   âŒ DeepSeek ä¹Ÿå¤±è´¥: {str(e2)[:100]}")
                raise Exception(f"æ‰€æœ‰ AI å¼•æ“éƒ½å¤±è´¥: Gemini={last_error}, DeepSeek={str(e2)}")
        
        if not text:
            raise Exception("AI å¼•æ“æœªè¿”å›ä»»ä½•å†…å®¹")
        
        # æ¸…ç†å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®°
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()
        
        # æ¸…ç†æ§åˆ¶å­—ç¬¦
        text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
        
        # è§£æ JSON
        cases = json.loads(text)
        
        if not isinstance(cases, list):
            cases = [cases]
        
        print(f"âœ… ä»æŠ¥å‘Šä¸­æå–åˆ° {len(cases)} ä¸ªæ¡ˆä¾‹")
        return cases
        
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {str(e)}")
        print(f"   åŸå§‹å“åº”å‰500å­—ç¬¦: {text[:500] if 'text' in locals() else 'N/A'}")
        return []


# ==================== å¤–éƒ¨è¡¥å…… ====================

def search_additional_cases(keywords: List[str], target_count: int = 50) -> List[Dict]:
    """
    ä½¿ç”¨ Tavily æœç´¢è¡¥å……æ¡ˆä¾‹ï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡æ•°é‡
    
    å‚æ•°:
        keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
        target_count: ç›®æ ‡æ¡ˆä¾‹æ•°é‡
    
    è¿”å›:
        è¡¥å……çš„æ¡ˆä¾‹åˆ—è¡¨
    """
    if not tavily_client:
        print("âš ï¸ Tavily æœªé…ç½®ï¼Œè·³è¿‡å¤–éƒ¨æœç´¢")
        return []
    
    all_cases = []
    
    for keyword in keywords:
        if len(all_cases) >= target_count:
            break
        
        try:
            print(f"\nğŸ” æœç´¢å…³é”®è¯: {keyword}")
            response = tavily_client.search(
                query=f"{keyword} insurance fraud case",
                search_depth="advanced",
                max_results=10,
                include_answer=True,
            )
            
            for item in response.get('results', []):
                if len(all_cases) >= target_count:
                    break
                
                # è¿™é‡Œå¯ä»¥è°ƒç”¨ deep_research_flow è¿›è¡Œæ·±åº¦åˆ†æ
                # æš‚æ—¶åªæ”¶é›† URL å’Œæ ‡é¢˜
                case_info = {
                    'case_name': item.get('title', ''),
                    'source_url': item.get('url', ''),
                    'content': item.get('content', ''),
                }
                all_cases.append(case_info)
        
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥ {keyword}: {str(e)}")
            continue
    
    print(f"âœ… å¤–éƒ¨æœç´¢è¡¥å…… {len(all_cases)} ä¸ªæ¡ˆä¾‹")
    return all_cases


# ==================== ç»“æ„åŒ–è½¬æ¢ ====================

def convert_to_seed_case_format(case_data: Dict) -> Dict:
    """
    å°†æå–çš„æ¡ˆä¾‹è½¬æ¢ä¸ºç§å­æ¡ˆä¾‹æ ¼å¼
    
    å‚æ•°:
        case_data: åŸå§‹æ¡ˆä¾‹æ•°æ®
    
    è¿”å›:
        æ ‡å‡†åŒ–çš„ç§å­æ¡ˆä¾‹æ•°æ®
    """
    # æ„å»º Process å­—æ®µï¼ˆæŒ‰ç…§ SIU æ ¼å¼ï¼‰
    process_parts = []
    
    # é£é™©ç”»åƒ
    scenario = f"æŠ•ä¿æ—¶é—´ï¼š{case_data.get('time', 'ä¿¡æ¯ç¼ºå¤±')}\n"
    scenario += f"ä¿é¢ï¼š{case_data.get('coverage_amount', 'ä¿¡æ¯ç¼ºå¤±')}\n"
    scenario += f"å‡ºé™©é—´éš”ï¼š{case_data.get('claim_interval', 'ä¿¡æ¯ç¼ºå¤±')}"
    process_parts.append(f"ã€é£é™©ç”»åƒã€‘\n{scenario}")
    
    # èˆå¼Šæ‰‹æ³•
    mo = case_data.get('modus_operandi', 'ä¿¡æ¯ç¼ºå¤±')
    process_parts.append(f"ã€èˆå¼Šæ‰‹æ³•(MO)ã€‘\n{mo}")
    
    # çº¢æ——æŒ‡æ ‡
    red_flags = case_data.get('red_flags', 'ä¿¡æ¯ç¼ºå¤±')
    process_parts.append(f"ã€çº¢æ——æŒ‡æ ‡(Red Flags)ã€‘\n{red_flags}")
    
    # æ ¸æŸ¥æ‰‹æ®µå»ºè®®
    investigation = case_data.get('investigative_tips', 'ä¿¡æ¯ç¼ºå¤±')
    process_parts.append(f"ã€æ ¸æŸ¥æ‰‹æ®µå»ºè®®ã€‘\n{investigation}")
    
    # æ ¸ä¿/é£æ§å¯ç¤º
    advice = case_data.get('underwriting_advice', 'ä¿¡æ¯ç¼ºå¤±')
    process_parts.append(f"ã€æ ¸ä¿/é£æ§å¯ç¤ºã€‘\n{advice}")
    
    process = "\n\n".join(process_parts)
    
    # æ„å»ºæ ‡å‡†æ ¼å¼
    seed_case = {
        'Time': case_data.get('time', 'æœªçŸ¥'),
        'Region': case_data.get('region', 'æœªçŸ¥'),
        'Characters': case_data.get('characters', 'æœªçŸ¥'),
        'Event': case_data.get('case_name', case_data.get('event', 'æœªçŸ¥')),
        'Process': process,
        'Result': case_data.get('result', 'æœªçŸ¥'),
        'Source_URL': case_data.get('source_url', f"internal_report_{case_data.get('case_name', 'unknown')}"),
        'Created_at': datetime.now().isoformat(),
        # æ–°å­—æ®µ
        'line_of_business': case_data.get('line_of_business', 'æœªçŸ¥'),
        'fraud_type': case_data.get('fraud_type', 'æœªçŸ¥'),
        'modus_operandi': case_data.get('modus_operandi', 'æœªçŸ¥'),
        'red_flags': case_data.get('red_flags', 'æœªçŸ¥'),
        'investigative_tips': case_data.get('investigative_tips', 'æœªçŸ¥'),
        'underwriting_advice': case_data.get('underwriting_advice', 'æœªçŸ¥'),
        'is_seed_case': True,
        'last_shown_at': None,
    }
    
    return seed_case


# ==================== æ•°æ®åº“æ“ä½œ ====================

def save_seed_cases_to_db(cases: List[Dict]) -> int:
    """
    æ‰¹é‡ä¿å­˜ç§å­æ¡ˆä¾‹åˆ°æ•°æ®åº“
    
    å‚æ•°:
        cases: ç§å­æ¡ˆä¾‹åˆ—è¡¨
    
    è¿”å›:
        æˆåŠŸä¿å­˜çš„æ•°é‡
    """
    if not supabase:
        print("âŒ Supabase æœªåˆå§‹åŒ–")
        return 0
    
    saved_count = 0
    
    for case in cases:
        try:
            insert_data = {
                'time': case.get('Time', 'æœªçŸ¥'),
                'region': case.get('Region', 'æœªçŸ¥'),
                'characters': case.get('Characters', 'æœªçŸ¥'),
                'event': case.get('Event', 'æœªçŸ¥'),
                'process': case.get('Process', 'æœªçŸ¥'),
                'result': case.get('Result', 'æœªçŸ¥'),
                'source_url': case.get('Source_URL', ''),
                'created_at': case.get('Created_at', datetime.now().isoformat()),
                # æ–°å­—æ®µ
                'line_of_business': case.get('line_of_business'),
                'fraud_type': case.get('fraud_type'),
                'modus_operandi': case.get('modus_operandi'),
                'red_flags': case.get('red_flags'),
                'investigative_tips': case.get('investigative_tips'),
                'underwriting_advice': case.get('underwriting_advice'),
                'is_seed_case': case.get('is_seed_case', True),
                'last_shown_at': case.get('last_shown_at'),
            }
            
            result = supabase.table('fraud_cases').insert(insert_data).execute()
            
            if result.data:
                saved_count += 1
                print(f"âœ… ä¿å­˜ç§å­æ¡ˆä¾‹: {case.get('Event', 'æœªçŸ¥')}")
            else:
                print(f"âš ï¸ ä¿å­˜å¤±è´¥: {case.get('Event', 'æœªçŸ¥')}")
        
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥ {case.get('Event', 'æœªçŸ¥')}: {str(e)}")
            continue
    
    return saved_count


# ==================== ä¸»æµç¨‹ ====================

def main():
    """ä¸»å‡½æ•°ï¼šæå–å¹¶æ„å»º50ä¸ªç§å­æ¡ˆä¾‹åº“"""
    print("=" * 70)
    print("ğŸŒ± GIFIA - ç§å­æ¡ˆä¾‹åº“æå–å™¨")
    print(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # æ£€æŸ¥ä¾èµ–
    if not DOCX_AVAILABLE:
        print("\nâŒ é”™è¯¯: python-docx æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install python-docx")
        return
    
    # æ£€æŸ¥ API Key
    if not GEMINI_API_KEY:
        print("âŒ é”™è¯¯: GEMINI_API_KEY æœªè®¾ç½®")
        return
    
    if not supabase:
        print("âŒ é”™è¯¯: Supabase æœªé…ç½®")
        return
    
    # 1. ä»æŠ¥å‘Šä¸­æå–æ¡ˆä¾‹
    print("\n" + "=" * 70)
    print("ğŸ“š æ­¥éª¤1: ä»ç ”ç©¶æŠ¥å‘Šä¸­æå–æ¡ˆä¾‹")
    print("=" * 70)
    
    report_files = [
        "å…¨çƒåŒ»ç–—ä¿é™©åæ¬ºè¯ˆæ·±åº¦ç ”ç©¶æŠ¥å‘Š.docx",
        "å…¨çƒå¯¿é™©æ¬ºè¯ˆæ·±åº¦ç ”ç©¶æŠ¥å‘Š.docx",
        "å…¨çƒé‡å¤§ç–¾ç—…ä¿é™©æ¬ºè¯ˆç”Ÿæ€ç ”ç©¶.docx",
        "å…¨çƒé•¿æœŸå®šæœŸå¯¿é™©äº§å“æ·±åº¦ç ”ç©¶æŠ¥å‘Š.docx",
    ]
    
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    base_dir = "/Users/tigerli/Desktop/å…¨çƒåä¿é™©æ¬ºè¯ˆè”ç›Ÿ"
    report_files = [os.path.join(base_dir, f) for f in report_files]
    
    extracted_cases = extract_cases_from_reports(report_files)
    
    # 2. è½¬æ¢ä¸ºç§å­æ¡ˆä¾‹æ ¼å¼
    print(f"\nğŸ“‹ æ­¥éª¤2: è½¬æ¢æ¡ˆä¾‹æ ¼å¼ï¼ˆå…± {len(extracted_cases)} ä¸ªï¼‰")
    seed_cases = []
    for case in extracted_cases:
        seed_case = convert_to_seed_case_format(case)
        seed_cases.append(seed_case)
    
    # 3. å¦‚æœä¸è¶³50ä¸ªï¼Œå¤–éƒ¨è¡¥å……
    target_count = 50
    if len(seed_cases) < target_count:
        print(f"\nğŸ” æ­¥éª¤3: å¤–éƒ¨æœç´¢è¡¥å……æ¡ˆä¾‹ï¼ˆå½“å‰ {len(seed_cases)}/{target_count}ï¼‰")
        
        keywords = [
            "Upcoding",
            "Unbundling",
            "Shadow Patients",
            "Pseudocide",
            "Incontestability Clause",
            "DMERx fraud",
            "medical insurance fraud case",
            "life insurance fraud case",
            "critical illness fraud",
        ]
        
        additional_cases = search_additional_cases(keywords, target_count - len(seed_cases))
        # TODO: å¯¹ additional_cases è¿›è¡Œæ·±åº¦åˆ†æï¼ˆè°ƒç”¨ deep_research_flowï¼‰
        # æš‚æ—¶è·³è¿‡ï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤
    
    # 4. ç”Ÿæˆé¢„è§ˆæ¸…å•
    print(f"\nğŸ“Š æ­¥éª¤4: ç”Ÿæˆé¢„è§ˆæ¸…å•ï¼ˆå…± {len(seed_cases)} ä¸ªæ¡ˆä¾‹ï¼‰")
    preview_file = "seed_cases_preview.json"
    with open(preview_file, 'w', encoding='utf-8') as f:
        json.dump(seed_cases, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… é¢„è§ˆæ¸…å•å·²ä¿å­˜åˆ°: {preview_file}")
    print(f"\nğŸ“‹ æ¡ˆä¾‹é¢„è§ˆï¼ˆå‰10ä¸ªï¼‰:")
    for i, case in enumerate(seed_cases[:10], 1):
        print(f"   {i}. {case.get('Event', 'æœªçŸ¥')} - {case.get('Region', 'æœªçŸ¥')}")
    
    print(f"\n{'='*70}")
    print("â¸ï¸  è¯·æ£€æŸ¥é¢„è§ˆæ¸…å•ï¼Œç¡®è®¤åè¿è¡Œä»¥ä¸‹å‘½ä»¤å…¥åº“ï¼š")
    print("   python3 seed_cases_extractor.py --import")
    print("=" * 70)


if __name__ == "__main__":
    import sys
    
    if "--import" in sys.argv:
        # å¯¼å…¥æ¨¡å¼ï¼šä»é¢„è§ˆæ–‡ä»¶è¯»å–å¹¶å…¥åº“
        print("=" * 70)
        print("ğŸ“¥ å¯¼å…¥æ¨¡å¼ï¼šä»é¢„è§ˆæ–‡ä»¶è¯»å–å¹¶å…¥åº“")
        print("=" * 70)
        
        preview_file = "seed_cases_preview.json"
        if not os.path.exists(preview_file):
            print(f"âŒ é¢„è§ˆæ–‡ä»¶ä¸å­˜åœ¨: {preview_file}")
            print("è¯·å…ˆè¿è¡Œæå–æ¨¡å¼ç”Ÿæˆé¢„è§ˆæ¸…å•")
            sys.exit(1)
        
        with open(preview_file, 'r', encoding='utf-8') as f:
            seed_cases = json.load(f)
        
        print(f"ğŸ“‹ ä»é¢„è§ˆæ–‡ä»¶è¯»å– {len(seed_cases)} ä¸ªæ¡ˆä¾‹")
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        formatted_cases = []
        for case in seed_cases:
            formatted_case = convert_to_seed_case_format(case)
            formatted_cases.append(formatted_case)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        print(f"\nğŸ’¾ å¼€å§‹æ‰¹é‡ä¿å­˜åˆ°æ•°æ®åº“...")
        saved_count = save_seed_cases_to_db(formatted_cases)
        
        print(f"\n{'='*70}")
        print(f"âœ… å¯¼å…¥å®Œæˆï¼šæˆåŠŸä¿å­˜ {saved_count}/{len(formatted_cases)} ä¸ªç§å­æ¡ˆä¾‹")
        print("=" * 70)
    else:
        # æå–æ¨¡å¼ï¼šç”Ÿæˆé¢„è§ˆæ¸…å•
        main()
