"""
GIFIA v4.0 - The Living Scout (24/7 å…¨çƒè‡ªåŠ¨ä¾¦å¯Ÿç³»ç»Ÿ)
é€’å½’æ‰«æä¸çƒ­ç‚¹æŠ“å–ï¼šè‡ªåŠ¨æå–å¤–éƒ¨å¼•ç”¨é“¾æ¥ï¼Œç›‘æ§çƒ­ç‚¹æ¡ˆä¾‹
"""

import os
import json
import time
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set
from urllib.parse import urlparse
import requests
from supabase import create_client, Client
import google.generativeai as genai
from tavily import TavilyClient
from openai import OpenAI

# ==================== ç¯å¢ƒå˜é‡é…ç½® ====================

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
tavily_client = TavilyClient(api_key=TAVILY_API_KEY) if TAVILY_API_KEY else None
genai.configure(api_key=GEMINI_API_KEY)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None

# ç›‘æ§ç™½åå•ï¼ˆ.org å’Œ .gov åŸŸåï¼‰
monitored_domains: Set[str] = set()

# ==================== AI åˆ†æå‡½æ•°ï¼ˆFailoverï¼‰ ====================

def get_ai_analysis(prompt: str) -> Optional[str]:
    """é€šç”¨AIåˆ†æå‡½æ•°ï¼šä¼˜å…ˆä½¿ç”¨ Geminiï¼Œå¤±è´¥åè‡ªåŠ¨åˆ‡æ¢åˆ° DeepSeek"""
    # 1) å°è¯• Gemini
    try:
        models_to_try = [
            "models/gemini-2.5-flash",
            "models/gemini-1.5-pro",
            "models/gemini-flash-latest",
        ]
        last_err = None
        for model_name in models_to_try:
            try:
                print("[Gemini] æ­£åœ¨åˆ†æ...")
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)
                text = (response.text or "").strip()
                if text:
                    return text
            except Exception as e:
                last_err = str(e)
                if any(k in str(e).lower() for k in ["quota", "rate", "429", "exceeded", "limit"]):
                    print("âš ï¸ Gemini é™é¢ï¼Œåˆ‡æ¢è‡³ DeepSeek...")
                    break
                continue
        if last_err and not any(k in last_err.lower() for k in ["quota", "rate", "429", "exceeded", "limit"]):
            print(f"âš ï¸ Gemini å¼‚å¸¸: {last_err[:120]}ï¼Œåˆ‡æ¢è‡³ DeepSeek...")
    except Exception as e:
        print(f"âš ï¸ Gemini åˆå§‹åŒ–å¤±è´¥: {str(e)}ï¼Œåˆ‡æ¢è‡³ DeepSeek...")

    # 2) å°è¯• DeepSeek
    try:
        if not DEEPSEEK_API_KEY:
            print("âŒ DeepSeek æœªé…ç½®")
            return None
        print("[DeepSeek] æ­£åœ¨æ¥ç®¡ä»»åŠ¡...")
        ds_client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")
        completion = ds_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±ä¿é™©åæ¬ºè¯ˆåˆ†æå¸ˆï¼Œæ“…é•¿ä»é•¿æ–‡ä¸­æŠ½å–ä¸¥æ ¼ç»“æ„åŒ–ä¿¡æ¯ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=2000,
        )
        text = (completion.choices[0].message.content or "").strip()
        return text if text else None
    except Exception as e:
        print(f"âŒ DeepSeek å¤±è´¥: {str(e)}")
        return None


# ==================== é€’å½’æ‰«æï¼šæå–å¤–éƒ¨å¼•ç”¨é“¾æ¥ ====================

def extract_external_links(content: str, base_url: str) -> List[str]:
    """
    ä»å†…å®¹ä¸­æå–å¤–éƒ¨å¼•ç”¨é“¾æ¥
    å¦‚æœæ˜¯ .org æˆ– .gov åŸŸåï¼ŒåŠ å…¥ç›‘æ§ç™½åå•
    """
    links = []
    
    # æå–æ‰€æœ‰ URL
    url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
    found_urls = re.findall(url_pattern, content)
    
    for url in found_urls:
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ .org æˆ– .gov åŸŸå
            if domain.endswith('.org') or domain.endswith('.gov'):
                links.append(url)
                monitored_domains.add(domain)
                print(f"   âœ… å‘ç°ç›‘æ§åŸŸå: {domain}")
        except:
            continue
    
    return links


def load_monitored_domains_from_db() -> Set[str]:
    """ä»æ•°æ®åº“åŠ è½½å·²ç›‘æ§çš„åŸŸå"""
    if not supabase:
        return set()
    
    try:
        # ä»å·²ä¿å­˜çš„æ¡ˆä¾‹ä¸­æå–åŸŸå
        result = supabase.table('fraud_cases').select('source_url').limit(1000).execute()
        domains = set()
        
        for row in result.data:
            url = row.get('source_url', '')
            if url:
                try:
                    parsed = urlparse(url)
                    domain = parsed.netloc.lower()
                    if domain.endswith('.org') or domain.endswith('.gov'):
                        domains.add(domain)
                except:
                    continue
        
        return domains
    except Exception as e:
        print(f"âš ï¸ åŠ è½½ç›‘æ§åŸŸåå¤±è´¥: {str(e)}")
        return set()


# ==================== çƒ­ç‚¹æŠ“å–ï¼šNews æ¨¡å¼æœç´¢ ====================

def search_hotspot_cases() -> List[Dict]:
    """
    ä½¿ç”¨ Tavily News æ¨¡å¼æœç´¢çƒ­ç‚¹æ¡ˆä¾‹
    æ¯30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼Œå‘ç°çªå‘é«˜å…³æ³¨åº¦æ¡ˆä¾‹
    """
    if not tavily_client:
        return []
    
    try:
        print("ğŸ”¥ [Hotspot] æ­£åœ¨æœç´¢çƒ­ç‚¹æ¡ˆä¾‹...")
        
        # çƒ­ç‚¹å…³é”®è¯
        hotspot_keywords = [
            "systemic insurance fraud",
            "massive insurance fraud scheme",
            "insurance fraud corruption",
            "widespread insurance fraud",
            "insurance fraud scandal",
        ]
        
        all_results = []
        
        for keyword in hotspot_keywords:
            try:
                response = tavily_client.search(
                    query=keyword,
                    search_depth="news",  # ä½¿ç”¨ news æ¨¡å¼
                    max_results=5,
                    include_answer=True,
                )
                
                for item in response.get('results', []):
                    # æ£€æŸ¥å…³æ³¨åº¦ï¼ˆåŸºäºåˆ†æ•°å’Œæ—¶é—´ï¼‰
                    score = item.get('score', 0)
                    if score > 0.7:  # é«˜å…³æ³¨åº¦é˜ˆå€¼
                        all_results.append({
                            'url': item.get('url', ''),
                            'title': item.get('title', ''),
                            'content': item.get('content', ''),
                            'score': score,
                            'is_hotspot': True,
                        })
            except Exception as e:
                print(f"âš ï¸ çƒ­ç‚¹æœç´¢å¤±è´¥ {keyword}: {str(e)}")
                continue
        
        print(f"âœ… [Hotspot] å‘ç° {len(all_results)} ä¸ªçƒ­ç‚¹æ¡ˆä¾‹")
        return all_results
        
    except Exception as e:
        print(f"âŒ [Hotspot] çƒ­ç‚¹æœç´¢å¤±è´¥: {str(e)}")
        return []


# ==================== å¸¸è§„æœç´¢ ====================

def search_fraud_cases(query: str = "Global insurance fraud case 2025 2026", max_results: int = 10) -> List[Dict]:
    """ä½¿ç”¨ Tavily API æœç´¢å…¨çƒä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹"""
    if not tavily_client:
        return []
    
    try:
        response = tavily_client.search(
            query=query,
            search_depth="advanced",
            max_results=max_results,
            include_answer=True,
            include_raw_content=False,
        )
        
        results = []
        for item in response.get('results', []):
            results.append({
                'url': item.get('url', ''),
                'title': item.get('title', ''),
                'content': item.get('content', ''),
                'score': item.get('score', 0),
                'is_hotspot': False,
            })
        
        print(f"âœ… æœç´¢åˆ° {len(results)} ä¸ªç»“æœ")
        return results
    except Exception as e:
        print(f"âŒ Tavily æœç´¢å¤±è´¥: {str(e)}")
        return []


# ==================== æ¡ˆä¾‹æå– ====================

def extract_case_info(url: str, title: str, content: str) -> Optional[Dict]:
    """
    æå–æ¡ˆä¾‹ä¿¡æ¯ï¼ˆä½¿ç”¨5ç»´åº¦ç»“æ„åŒ–æ ¼å¼ï¼‰
    """
    prompt = f"""
ä½ æ˜¯ä¸€ä½å…¨çƒå¯¿é™©ä¸å¥åº·é™©åæ¬ºè¯ˆä¸“å®¶ï¼ˆSIU èµ„æ·±è°ƒæŸ¥å‘˜ï¼‰ã€‚è¯·ä»ä»¥ä¸‹ç½‘é¡µä¿¡æ¯ä¸­æå–ä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹ï¼Œå¹¶æŒ‰ç…§ä¸“ä¸šç®€æŠ¥æ ¼å¼è¾“å‡ºã€‚

ç½‘é¡µæ ‡é¢˜: {title}
ç½‘é¡µé“¾æ¥: {url}
ç½‘é¡µå†…å®¹æ‘˜è¦:
{content}

ã€åˆ†æä»»åŠ¡ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ã€ç®€æŠ¥æ ¼å¼ã€‘è¾“å‡ºï¼Œæ‰€æœ‰å†…å®¹å¿…é¡»ç”¨ä¸­æ–‡å¡«å†™ï¼š

1. **Time (æ—¶é—´)**: äº‹ä»¶å‘ç”Ÿæˆ–åˆ¤å†³çš„å…·ä½“æ—¶é—´ï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
2. **Region (åœ°åŒº)**: å›½å®¶åŠåŸå¸‚
3. **Characters (äººç‰©/å®ä½“)**: æ¶‰æ¡ˆäººèº«ä»½ã€ä¿é™©å…¬å¸ã€ä¸­ä»‹æˆ–åŒ»ç–—æœºæ„
4. **Event (äº‹ä»¶)**: æ¬ºè¯ˆç±»å‹æ¦‚æ‹¬

5. **Process (ç»è¿‡)**: å¿…é¡»ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹5ä¸ªæ ‡é¢˜ï¼Œç¦æ­¢æè¿°æ€§æ–‡å­—ï¼š

   **ã€é£é™©ç”»åƒã€‘**
   æŠ•ä¿æ—¶é—´ã€ä¿é¢ã€å‡ºé™©é—´éš”
   
   **ã€èˆå¼Šæ‰‹æ³•(MO)ã€‘**
   å…·ä½“æ¬ºè¯ˆæ‰‹æ®µ
   
   **ã€çº¢æ——æŒ‡æ ‡(Red Flags)ã€‘**
   è§¦å‘è­¦æŠ¥çš„å¼‚å¸¸æŒ‡æ ‡
   
   **ã€æ ¸æŸ¥æ‰‹æ®µå»ºè®®ã€‘**
   ç¡®è¯æ–¹å¼å’Œè°ƒæŸ¥æ–¹æ³•
   
   **ã€æ ¸ä¿/é£æ§å¯ç¤ºã€‘**
   é¢„è­¦ä»·å€¼å’Œé£æ§å»ºè®®

6. **Result (ç»“æœ)**: åˆ¤å†³ç»“æœã€ç½šé‡‘æˆ–æ³•å¾‹åˆ¶è£

ã€è¾“å‡ºè¦æ±‚ã€‘
- å¿…é¡»ä»¥çº¯ JSON æ ¼å¼è¾“å‡º
- Process å­—æ®µå¿…é¡»åŒ…å«5ä¸ªæ ‡é¢˜çš„è¯¦ç»†å†…å®¹ï¼Œè‡³å°‘ 500 å­—
- å­—æ®µåä½¿ç”¨è‹±æ–‡ï¼ˆTime, Region, Characters, Event, Process, Resultï¼‰

ç°åœ¨è¯·å¼€å§‹åˆ†æï¼š
"""

    try:
        text = get_ai_analysis(prompt)
        if not text:
            return None
        
        # æ¸…ç† JSON
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()
        text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
        
        case_data = json.loads(text)
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['Time', 'Region', 'Characters', 'Event', 'Process', 'Result']
        for field in required_fields:
            if field not in case_data:
                case_data[field] = "æœªçŸ¥"
        
        # æ·»åŠ å…ƒæ•°æ®
        case_data['Source_URL'] = url
        case_data['Created_at'] = datetime.now().isoformat()
        
        return case_data
        
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {str(e)}")
        return None


# ==================== é€’å½’æ‰«æï¼šå¤„ç†å¤–éƒ¨é“¾æ¥ ====================

def process_external_links(case_content: str, base_url: str) -> List[Dict]:
    """
    ä»æ¡ˆä¾‹å†…å®¹ä¸­æå–å¤–éƒ¨é“¾æ¥ï¼Œå¦‚æœæ˜¯ç›‘æ§åŸŸååˆ™æ·±åº¦æŠ“å–
    """
    external_links = extract_external_links(case_content, base_url)
    
    if not external_links:
        return []
    
    print(f"ğŸ”— [Recursive] å‘ç° {len(external_links)} ä¸ªå¤–éƒ¨é“¾æ¥")
    
    new_cases = []
    for link in external_links[:5]:  # é™åˆ¶æœ€å¤šå¤„ç†5ä¸ª
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if check_duplicate(link):
                continue
            
            # æŠ“å–å†…å®¹
            response = requests.get(link, timeout=30, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            if response.status_code == 200:
                # ç®€å•æå–æ–‡æœ¬
                content = response.text[:5000]  # é™åˆ¶é•¿åº¦
                title = link.split('/')[-1]
                
                # æå–æ¡ˆä¾‹ä¿¡æ¯
                case_data = extract_case_info(link, title, content)
                if case_data:
                    new_cases.append(case_data)
                    print(f"   âœ… ä»å¤–éƒ¨é“¾æ¥æå–æ¡ˆä¾‹: {case_data.get('Event', 'æœªçŸ¥')}")
        except Exception as e:
            print(f"   âš ï¸ å¤„ç†å¤–éƒ¨é“¾æ¥å¤±è´¥ {link}: {str(e)}")
            continue
    
    return new_cases


# ==================== æ•°æ®åº“æ“ä½œ ====================

def check_duplicate(url: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨"""
    if not supabase:
        return False
    try:
        result = supabase.table('fraud_cases').select('id').eq('source_url', url).execute()
        return len(result.data) > 0
    except:
        return False


def save_to_supabase(case_data: Dict, source: str = 'auto_scout') -> bool:
    """ä¿å­˜åˆ°æ•°æ®åº“"""
    if not supabase:
        return False
    
    try:
        insert_data = {
            'time': case_data.get('Time', 'æœªçŸ¥'),
            'region': case_data.get('Region', 'æœªçŸ¥'),
            'characters': case_data.get('Characters', 'æœªçŸ¥'),
            'event': case_data.get('Event', 'æœªçŸ¥'),
            'process': case_data.get('Process', 'æœªçŸ¥'),
            'result': case_data.get('Result', 'æœªçŸ¥'),
            'source_url': case_data.get('Source_URL', ''),
            'created_at': case_data.get('Created_at', datetime.now().isoformat()),
            'source': source,  # æ ‡è®°æ¥æº
        }
        
        result = supabase.table('fraud_cases').insert(insert_data).execute()
        
        if result.data:
            print(f"âœ… ä¿å­˜æˆåŠŸ: {insert_data['event']}")
            return True
        return False
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
        return False


# ==================== ä¸»æµç¨‹ ====================

def main():
    """ä¸»å‡½æ•°ï¼š24/7 è‡ªåŠ¨ä¾¦å¯Ÿ"""
    print("=" * 70)
    print("ğŸŒ GIFIA v4.0 - The Living Scout (24/7 å…¨çƒè‡ªåŠ¨ä¾¦å¯Ÿ)")
    print(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # éªŒè¯é…ç½®
    missing_keys = []
    if not TAVILY_API_KEY:
        missing_keys.append("TAVILY_API_KEY")
    if not GEMINI_API_KEY:
        missing_keys.append("GEMINI_API_KEY")
    if not SUPABASE_URL:
        missing_keys.append("SUPABASE_URL")
    if not SUPABASE_KEY:
        missing_keys.append("SUPABASE_KEY")
    
    if missing_keys:
        print(f"âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ API Key: {', '.join(missing_keys)}")
        import sys
        sys.exit(1)
    
    # åŠ è½½ç›‘æ§åŸŸå
    global monitored_domains
    monitored_domains = load_monitored_domains_from_db()
    print(f"ğŸ“‹ å·²åŠ è½½ {len(monitored_domains)} ä¸ªç›‘æ§åŸŸå")
    
    saved_count = 0
    skipped_count = 0
    failed_count = 0
    
    # 1. çƒ­ç‚¹æœç´¢ï¼ˆæ¯30åˆ†é’Ÿï¼‰
    print("\n" + "=" * 70)
    print("ğŸ”¥ æ­¥éª¤1: çƒ­ç‚¹æ¡ˆä¾‹æœç´¢ï¼ˆNews æ¨¡å¼ï¼‰")
    print("=" * 70)
    
    hotspot_cases = search_hotspot_cases()
    for case in hotspot_cases:
        if check_duplicate(case['url']):
            skipped_count += 1
            continue
        
        case_data = extract_case_info(case['url'], case['title'], case['content'])
        if case_data:
            if save_to_supabase(case_data, source='hotspot'):
                saved_count += 1
                
                # é€’å½’æ‰«æå¤–éƒ¨é“¾æ¥
                external_cases = process_external_links(case['content'], case['url'])
                for ext_case in external_cases:
                    if save_to_supabase(ext_case, source='recursive'):
                        saved_count += 1
        else:
            failed_count += 1
    
    # 2. å¸¸è§„æœç´¢
    print("\n" + "=" * 70)
    print("ğŸ“¡ æ­¥éª¤2: å¸¸è§„æ¡ˆä¾‹æœç´¢")
    print("=" * 70)
    
    search_results = search_fraud_cases(max_results=5)
    for result in search_results:
        if check_duplicate(result['url']):
            skipped_count += 1
            continue
        
        case_data = extract_case_info(result['url'], result['title'], result['content'])
        if case_data:
            if save_to_supabase(case_data, source='auto_scout'):
                saved_count += 1
                
                # é€’å½’æ‰«æå¤–éƒ¨é“¾æ¥
                external_cases = process_external_links(result['content'], result['url'])
                for ext_case in external_cases:
                    if save_to_supabase(ext_case, source='recursive'):
                        saved_count += 1
        else:
            failed_count += 1
    
    # è¾“å‡ºç»Ÿè®¡
    print("\n" + "=" * 70)
    print("ğŸ“Š ä¾¦å¯Ÿå®Œæˆç»Ÿè®¡")
    print("=" * 70)
    print(f"âœ… æˆåŠŸä¿å­˜: {saved_count} ä¸ªæ¡ˆä¾‹")
    print(f"â­ï¸  è·³è¿‡ï¼ˆé‡å¤ï¼‰: {skipped_count} ä¸ªæ¡ˆä¾‹")
    print(f"âŒ å¤±è´¥: {failed_count} ä¸ªæ¡ˆä¾‹")
    print(f"ğŸ“‹ ç›‘æ§åŸŸå: {len(monitored_domains)} ä¸ª")
    print("=" * 70)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        import sys
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        import sys
        sys.exit(1)
