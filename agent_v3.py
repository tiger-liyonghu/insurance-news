"""
Global Insurance Fraud Intelligence Agent (GIFIA) v3.0 - äº‘ç«¯æƒ…æŠ¥ç«™
æ·±åº¦åä½œæ¨¡å¼ï¼šScout -> Researcher -> Analyst -> Validator
è‡ªåŠ¨åŒ–æŠ“å–è„šæœ¬ï¼šä½¿ç”¨ Firecrawl + Gemini 1.5 Pro æ·±åº¦ç ”ç©¶
"""

import os
import json
import time
import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from difflib import SequenceMatcher
from supabase import create_client, Client
import google.generativeai as genai
from tavily import TavilyClient
from openai import OpenAI

# å°è¯•å¯¼å…¥ Firecrawlï¼ˆå…¼å®¹ä¸åŒçš„å¯¼å…¥æ–¹å¼ï¼‰
try:
    from firecrawl import FirecrawlApp
except ImportError:
    try:
        from firecrawl.firecrawl import FirecrawlApp
    except ImportError:
        try:
            from firecrawl_py import FirecrawlApp
        except ImportError:
            FirecrawlApp = None

# ==================== ç¯å¢ƒå˜é‡é…ç½® ====================

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")  # å¤‡ä»½å¼•æ“ï¼šDeepSeek
FIRECRAWL_API_KEY = os.getenv("FIRECRAWL_API_KEY")  # æ–°å¢ï¼šFirecrawl API
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
tavily_client = TavilyClient(api_key=TAVILY_API_KEY)
genai.configure(api_key=GEMINI_API_KEY)

# åˆå§‹åŒ– Firecrawl Appï¼ˆå¦‚æœ API Key å­˜åœ¨ï¼‰
firecrawl_app = None
if FIRECRAWL_API_KEY and FirecrawlApp:
    try:
        firecrawl_app = FirecrawlApp(api_key=FIRECRAWL_API_KEY)
    except Exception as e:
        print(f"âš ï¸ Firecrawl åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        firecrawl_app = None

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None

# ==================== Agent 1: The Scout (ä¾¦å¯Ÿå‘˜) ====================

class ScoutAgent:
    """
    ä¾¦å¯Ÿå‘˜ Agentï¼šè´Ÿè´£æœç´¢é«˜è´¨é‡çš„ä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹
    ä½¿ç”¨ Tavily API æ‰§è¡Œé«˜çº§æœç´¢
    """
    
    def __init__(self, tavily_client: TavilyClient):
        self.client = tavily_client
        
        # ä¸“ä¸šå…³é”®è¯ï¼šç¡®ä¿æ‰¾åˆ°å…·ä½“æ¡ˆä¾‹è€Œéé€šç”¨æ–‡ç« 
        self.case_specific_keywords = [
            'charged with fraud',
            'convicted of fraud',
            'fraud case',
            'fraud scheme',
            'arrested for insurance fraud',
            'sentenced for insurance fraud'
        ]
        
        # ä¿é™©ç±»å‹å…³é”®è¯ï¼šåªå…³æ³¨å¯¿é™©ã€å¥åº·é™©ã€æ„å¤–é™©
        self.insurance_types = [
            'life insurance fraud',
            'health insurance fraud',
            'accident insurance fraud',
            'medical insurance fraud',
            'disability insurance fraud'
        ]
        
        # æ’é™¤å…³é”®è¯ï¼šæ’é™¤è´¢äº§ä¿é™©
        self.exclude_keywords = [
            'property insurance',
            'auto insurance fraud',
            'car insurance fraud',
            'vehicle insurance'
        ]
    
    def build_query(self) -> str:
        """æ„å»ºå¢å¼ºçš„æœç´¢æŸ¥è¯¢"""
        essential_case_keywords = " OR ".join(self.case_specific_keywords[:3])
        essential_insurance_types = " OR ".join(self.insurance_types[:3])
        enhanced_query = f"{essential_case_keywords} {essential_insurance_types} -property insurance -auto insurance 2025 2026"
        
        if len(enhanced_query) > 400:
            enhanced_query = "life insurance fraud case OR health insurance fraud case OR accident insurance fraud case -property -auto 2025 2026"
        
        return enhanced_query
    
    def search(self, max_results: int = 15) -> List[Dict]:
        """
        æœç´¢å…¨çƒä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹ï¼ˆé«˜çº§æ¨¡å¼ï¼‰
        
        è¿”å›:
            æœç´¢ç»“æœåˆ—è¡¨ï¼ŒæŒ‰è´¨é‡åˆ†æ•°æ’åº
        """
        try:
            enhanced_query = self.build_query()
            
            print(f"ğŸ” [Scout] æ­£åœ¨æ‰§è¡Œé«˜çº§æœç´¢...")
            print(f"   ğŸ“‹ å…³é”®è¯: {enhanced_query[:120]}...")
            
            response = self.client.search(
                query=enhanced_query,
                search_depth="advanced",  # é«˜çº§æœç´¢æ¨¡å¼
                max_results=max_results,
                include_domains=None,
                include_answer=True,
                include_raw_content=False,
            )
            
            results = []
            for item in response.get('results', []):
                url = item.get('url', '')
                title = item.get('title', '').lower()
                content = item.get('content', '').lower()
                
                # è¿‡æ»¤é€šç”¨æ–‡ç« å’Œè´¢äº§ä¿é™©
                should_exclude = False
                generic_keywords = ['market report', 'market size', 'industry outlook', 'forecast', 'trends']
                for keyword in generic_keywords:
                    if keyword in title or keyword in content:
                        should_exclude = True
                        break
                
                for exclude_keyword in self.exclude_keywords:
                    if exclude_keyword in title or exclude_keyword in content:
                        should_exclude = True
                        break
                
                has_case_keyword = any(kw in title or kw in content for kw in self.case_specific_keywords)
                
                if not should_exclude and has_case_keyword:
                    results.append({
                        'url': url,
                        'title': item.get('title', ''),
                        'content': item.get('content', ''),
                        'score': item.get('score', 0)
                    })
            
            results.sort(key=lambda x: x.get('score', 0), reverse=True)
            
            print(f"âœ… [Scout] æœç´¢å®Œæˆï¼šæ‰¾åˆ° {len(results)} ä¸ªç¬¦åˆæ¡ä»¶çš„æ¡ˆä¾‹")
            return results
            
        except Exception as e:
            print(f"âŒ [Scout] æœç´¢å¤±è´¥: {str(e)}")
            return []


# ==================== Agent 2: The Researcher (æ·±åº¦æŠ“å–å‘˜) ====================

class ResearcherAgent:
    """
    æ·±åº¦æŠ“å–å‘˜ Agentï¼šä½¿ç”¨ Firecrawl æŠ“å– Markdown æ ¼å¼çš„å…¨æ–‡
    ä¸¥ç¦åªçœ‹æ‘˜è¦ï¼Œå¿…é¡»è·å–å®Œæ•´å†…å®¹
    """
    
    def __init__(self, firecrawl_app: Optional[FirecrawlApp]):
        self.app = firecrawl_app
    
    def scrape_url(self, url: str) -> Optional[Dict]:
        """
        ä½¿ç”¨ Firecrawl æŠ“å– URL çš„ Markdown æ ¼å¼å…¨æ–‡
        
        å‚æ•°:
            url: ç›®æ ‡ç½‘é¡µ URL
        
        è¿”å›:
            åŒ…å« Markdown å…¨æ–‡çš„å­—å…¸ï¼Œæˆ– Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        if not self.app:
            print(f"âŒ [Researcher] Firecrawl API Key æœªè®¾ç½®")
            return None
        
        try:
            print(f"ğŸ“¥ [Researcher] æ­£åœ¨æ·±åº¦æ‰«æ: {url[:80]}...")
            print(f"   ğŸ”„ è°ƒç”¨ Firecrawl æå– Markdown å…¨æ–‡...")
            
            # è°ƒç”¨ FirecrawlApp çš„ scrape æ–¹æ³•
            # Firecrawl çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼šapp.scrape(url) - åªä¼  URL
            result = self.app.scrape(url)
            
            # Firecrawl è¿”å› Document å¯¹è±¡
            if result:
                # å°è¯•è·å– markdown å†…å®¹
                markdown_content = None
                
                # æ–¹æ³•1: ç›´æ¥è®¿é—® markdown å±æ€§
                if hasattr(result, 'markdown'):
                    try:
                        markdown_content = result.markdown
                    except:
                        pass
                
                # æ–¹æ³•2: é€šè¿‡ dict() æ–¹æ³•è®¿é—®ï¼ˆFirecrawl v2 çš„æ–¹å¼ï¼‰
                if not markdown_content and hasattr(result, 'dict'):
                    try:
                        result_dict = result.dict()
                        markdown_content = result_dict.get('markdown', '') or result_dict.get('content', '')
                    except:
                        pass
                
                # æ–¹æ³•3: å¦‚æœæ˜¯å­—å…¸æ ¼å¼
                if not markdown_content and isinstance(result, dict):
                    markdown_content = result.get('markdown') or result.get('content', '')
                
                # æ–¹æ³•4: å°è¯•è®¿é—® __dict__
                if not markdown_content:
                    try:
                        result_dict = result.__dict__ if hasattr(result, '__dict__') else {}
                        markdown_content = result_dict.get('markdown') or result_dict.get('content', '')
                    except:
                        pass
                
                if markdown_content and len(markdown_content) > 0:
                    content_length = len(markdown_content)
                    
                    print(f"âœ… [Researcher] æ·±åº¦æ‰«æå®Œæˆ: è·å– {content_length} å­—ç¬¦ Markdown å…¨æ–‡")
                    
                    if content_length < 500:
                        print(f"âš ï¸ [Researcher] è­¦å‘Š: å†…å®¹è¿‡çŸ­ ({content_length} å­—ç¬¦)ï¼Œå¯èƒ½æœªå®Œå…¨æŠ“å–")
                    
                    # è·å–å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                    metadata = {}
                    if hasattr(result, 'metadata'):
                        metadata = result.metadata if isinstance(result.metadata, dict) else {}
                    elif isinstance(result, dict):
                        metadata = result.get('metadata', {})
                    
                    return {
                        'url': url,
                        'markdown_content': markdown_content,
                        'content_length': content_length,
                        'metadata': metadata
                    }
                else:
                    print(f"âŒ [Researcher] æŠ“å–å¤±è´¥: æœªè¿”å› Markdown å†…å®¹")
                    print(f"   è¿”å›ç»“æœç±»å‹: {type(result)}")
                    if hasattr(result, '__dict__'):
                        print(f"   è¿”å›ç»“æœå±æ€§: {list(result.__dict__.keys())[:5]}")
                    return None
            else:
                print(f"âŒ [Researcher] æŠ“å–å¤±è´¥: è¿”å›ç»“æœä¸º None")
                return None
                
        except Exception as e:
            print(f"âŒ [Researcher] æ·±åº¦æ‰«æå¤±è´¥: {str(e)}")
            return None


# ==================== Agent 3: The Analyst (æ·±åº¦åˆ†æå¸ˆ) ====================

class AnalystAgent:
    """
    æ·±åº¦åˆ†æå¸ˆ Agentï¼šä½¿ç”¨ Gemini 1.5 Pro æ·±åº¦åˆ†æå…¨æ–‡
    ç‰¹åˆ«æŒ‡ä»¤ï¼šå¿…é¡»æŒ–æ˜æ¡ˆä»¶ä¸­çš„"ç ´ç»½ç»†èŠ‚ (The Red Flag)"
    """
    
    def __init__(self, gemini_api_key: str):
        genai.configure(api_key=gemini_api_key)
        self.model = None
        self._initialize_model()
    
    def _initialize_model(self):
        """åˆå§‹åŒ– Gemini æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨ Proï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ Flashï¼‰"""
        models_to_try = [
            'models/gemini-2.5-flash',  # ä¼˜å…ˆä½¿ç”¨æœ€æ–° Flashï¼ˆæ›´ç¨³å®šï¼‰
            'models/gemini-2.0-flash',
            'models/gemini-1.5-pro',  # å¦‚æœå¯ç”¨ï¼Œä½¿ç”¨ Pro
            'models/gemini-flash-latest'
        ]
        
        last_error = None
        for model_name in models_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                # ç®€å•æµ‹è¯•è°ƒç”¨
                response = model.generate_content("test")
                self.model = model
                print(f"âœ… [Analyst] ä½¿ç”¨ Gemini æ¨¡å‹: {model_name}")
                return
            except Exception as e:
                last_error = str(e)
                continue
        
        # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨æœ€æ–° Flash ä½œä¸ºé»˜è®¤ï¼ˆå³ä½¿å¯èƒ½å¤±è´¥ï¼‰
        print(f"âš ï¸ [Analyst] æ— æ³•éªŒè¯æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ models/gemini-2.5-flash")
        if last_error:
            print(f"   æœ€åçš„é”™è¯¯: {last_error[:100]}")
        self.model = genai.GenerativeModel('models/gemini-2.5-flash')
    
    def analyze(self, url: str, title: str, markdown_content: str) -> Optional[Dict]:
        """
        æ·±åº¦åˆ†ææ¡ˆä¾‹ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯
        ç‰¹åˆ«å¼ºè°ƒï¼šå¿…é¡»æŒ–æ˜"ç ´ç»½ç»†èŠ‚ (The Red Flag)"
        
        å‚æ•°:
            url: åŸå§‹é“¾æ¥
            title: æ ‡é¢˜
            markdown_content: Firecrawl æŠ“å–çš„ Markdown å…¨æ–‡
        
        è¿”å›:
            ç»“æ„åŒ–æ¡ˆä¾‹æ•°æ®å­—å…¸
        """
        # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¶…å‡º token é™åˆ¶
        max_length = 50000
        if len(markdown_content) > max_length:
            markdown_content = markdown_content[:max_length] + "\n\n[å†…å®¹å·²æˆªæ–­...]"
        
        prompt = f"""
ä½ æ˜¯ä¸€ä½å…¨çƒå¯¿é™©ä¸å¥åº·é™©åæ¬ºè¯ˆä¸“å®¶ï¼ˆSIU èµ„æ·±è°ƒæŸ¥å‘˜ï¼‰ã€‚è¯·ä»ä»¥ä¸‹ç½‘é¡µçš„å®Œæ•´ Markdown å†…å®¹ä¸­ï¼Œæ·±åº¦åˆ†æä¿é™©æ¬ºè¯ˆæ¡ˆä¾‹ï¼Œå¹¶æŒ‰ç…§ä¸“ä¸šç®€æŠ¥æ ¼å¼è¾“å‡ºç»“æ„åŒ–æ‘˜è¦ã€‚

ã€ç½‘é¡µä¿¡æ¯ã€‘
æ ‡é¢˜: {title}
é“¾æ¥: {url}

ã€å®Œæ•´ Markdown å†…å®¹ã€‘
{markdown_content}

ã€åˆ†æä»»åŠ¡ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ã€ç®€æŠ¥æ ¼å¼ã€‘è¾“å‡ºç»“æ„åŒ–æ‘˜è¦ï¼Œæ‰€æœ‰å†…å®¹å¿…é¡»ç”¨ä¸­æ–‡å¡«å†™ï¼š

1. **Time (æ—¶é—´)**: äº‹ä»¶å‘ç”Ÿæˆ–åˆ¤å†³çš„å…·ä½“æ—¶é—´
   - æ ¼å¼ï¼šYYYY-MM-DD æˆ– YYYYå¹´MMæœˆDDæ—¥
   - å¦‚æœæ–‡ä¸­æ²¡æœ‰æ˜ç¡®æ—¶é—´ï¼Œå¡«å†™"æœªçŸ¥"

2. **Region (åœ°åŒº)**: å›½å®¶åŠåŸå¸‚
   - ä¾‹å¦‚ï¼šç¾å›½çº½çº¦ã€ä¸­å›½ä¸Šæµ·ã€è‹±å›½ä¼¦æ•¦
   - å¦‚æœæœªæåŠï¼Œå¡«å†™"æœªçŸ¥"

3. **Characters (äººç‰©/å®ä½“)**: æ¶‰æ¡ˆäººèº«ä»½ã€ä¿é™©å…¬å¸ã€ä¸­ä»‹æˆ–åŒ»ç–—æœºæ„
   - ç”¨é€—å·åˆ†éš”å¤šä¸ªå®ä½“
   - å¦‚æœæœªæåŠï¼Œå¡«å†™"æœªçŸ¥"

4. **Event (äº‹ä»¶)**: æ¬ºè¯ˆç±»å‹æ¦‚æ‹¬
   - ä¾‹å¦‚ï¼šå¯¿é™©æ¬ºè¯ˆã€å¥åº·é™©æ¬ºè¯ˆã€åŒ»ç–—ä¿é™©æ¬ºè¯ˆã€æ„å¤–é™©è™šå‡ç†èµ”

5. **Process (ç»è¿‡)**: ã€é‡ç‚¹å­—æ®µã€‘æŒ‰ç…§ SIU ä¸“ä¸šç®€æŠ¥æ ¼å¼ï¼Œä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹5ä¸ªæ ‡é¢˜ï¼Œç¦æ­¢ä½¿ç”¨æè¿°æ€§æ–‡å­—ï¼Œåªè¾“å‡ºç»“æ„åŒ–å†…å®¹ï¼š

   **ã€é£é™©ç”»åƒã€‘**
   - æŠ•ä¿æ—¶é—´ã€æŠ•ä¿äººä¿¡æ¯ã€æŠ•ä¿åŠ¨æœºã€å¥åº·çŠ¶å†µå£°æ˜
   - ä¿é™©é‡‘é¢ã€ä¿é™©ç±»å‹ã€ä¿éšœèŒƒå›´
   - å‡ºé™©æ—¶é—´ã€å‡ºé™©é—´éš”ï¼ˆæŠ•ä¿åå¤šä¹…å‡ºé™©ï¼‰ã€æ˜¯å¦åœ¨ç­‰å¾…æœŸå†…ã€æ˜¯å¦åœ¨çŠ¹è±«æœŸå†…
   - å¦‚æœæ–‡ä¸­æœªæåŠï¼Œæ ‡æ³¨"ä¿¡æ¯ç¼ºå¤±"
   
   **ã€èˆå¼Šæ‰‹æ³•(MO)ã€‘**
   - å…·ä½“æ¬ºè¯ˆæ‰‹æ®µï¼ˆæŒ‚åºŠä½é™¢ã€æµ·å¤–å‡æ”¶æ®ã€ä¼ªé€ åŒ»ç–—è®°å½•ã€è™šå‡è¯Šæ–­è¯æ˜ã€å¤¸å¤§ç—…æƒ…ã€é‡å¤ç†èµ”ç­‰ï¼‰
   - ä½¿ç”¨çš„æŠ€æœ¯ã€å·¥å…·ã€æ–‡ä»¶ã€è®°å½•
   - æ¶‰åŠçš„äººå‘˜ã€æœºæ„
   - å¦‚æœæ–‡ä¸­æœªæåŠï¼Œæ ‡æ³¨"ä¿¡æ¯ç¼ºå¤±"
   
   **ã€çº¢æ——æŒ‡æ ‡(Red Flags)ã€‘**
   - ç†èµ”ä¸­è§¦å‘çš„è­¦æŠ¥ï¼ˆç—…å†é€»è¾‘çŸ›ç›¾ã€è´¢åŠ¡çŠ¶å†µä¸ç¬¦ã€æ—¶é—´çº¿å¼‚å¸¸ã€åŒ»ç–—è®°å½•ä¸ä¸€è‡´ã€è¯Šæ–­ä¸ç—‡çŠ¶ä¸ç¬¦ã€åŒ»é™¢èµ„è´¨å¯ç–‘ç­‰ï¼‰
   - ç³»ç»Ÿæ£€æµ‹åˆ°çš„å¼‚å¸¸æŒ‡æ ‡
   - äººå·¥å®¡æ ¸å‘ç°çš„ç–‘ç‚¹
   - **è¿™æ˜¯é‡ç‚¹å­—æ®µï¼Œå¿…é¡»è¯¦ç»†åˆ—å‡ºï¼Œå¦‚æœæ–‡ä¸­æœªæåŠï¼Œæ˜ç¡®æ ‡æ³¨"ä¿¡æ¯ç¼ºå¤±"**
   
   **ã€æ ¸æŸ¥æ‰‹æ®µå»ºè®®ã€‘**
   - ç¡®è¯æ–¹å¼ï¼ˆåŒ»ä¿å¤§æ•°æ®æ¯”å¯¹ã€çº¿ä¸‹èµ°è®¿ã€ç¬¬ä¸‰æ–¹è°ƒæŸ¥ã€è´¢åŠ¡å®¡è®¡ã€åŒ»ç–—è®°å½•éªŒè¯ã€ä¸“å®¶ä¼šè¯Šã€èƒŒæ™¯è°ƒæŸ¥ç­‰ï¼‰
   - ä½¿ç”¨çš„æŠ€æœ¯æ‰‹æ®µï¼ˆæ•°æ®æŒ–æ˜ã€è¡Œä¸ºåˆ†æã€ç½‘ç»œè¿½è¸ªç­‰ï¼‰
   - è¯æ®æ”¶é›†æ–¹æ³•
   - å¦‚æœæ–‡ä¸­æœªæåŠï¼Œæ ‡æ³¨"ä¿¡æ¯ç¼ºå¤±"
   
   **ã€æ ¸ä¿/é£æ§å¯ç¤ºã€‘**
   - å‰ç«¯æ ¸ä¿é¢„è­¦ä»·å€¼
   - åº”å»ºç«‹çš„é£æ§è§„åˆ™ï¼ˆæŠ•ä¿åçŸ­æœŸå†…å‡ºé™©é¢„è­¦ã€ç‰¹å®šåŒ»é™¢é»‘åå•ã€å¤§é¢ç†èµ”äºŒæ¬¡å®¡æ ¸ç­‰ï¼‰
   - å‰ç«¯é£é™©è¯†åˆ«æ–¹æ³•ï¼ˆæŠ•ä¿äººè´¢åŠ¡çŠ¶å†µæ ¸æŸ¥ã€åŒ»ç–—è®°å½•äº¤å‰éªŒè¯ã€ç­‰å¾…æœŸç›‘æ§ç­‰ï¼‰
   - ç³»ç»ŸåŒ–æ”¹è¿›å»ºè®®
   - å¦‚æœæ–‡ä¸­æœªæåŠï¼Œå¯åŸºäºæ¡ˆä¾‹ç‰¹ç‚¹ç»™å‡ºä¸“ä¸šå»ºè®®

6. **Result (ç»“æœ)**: åˆ¤å†³ç»“æœã€ç½šé‡‘æˆ–æ³•å¾‹åˆ¶è£
   - åŒ…æ‹¬ï¼šåˆ‘æœŸã€ç½šæ¬¾é‡‘é¢ã€æ°‘äº‹èµ”å¿ã€è¡Œä¸šç¦å…¥ç­‰
   - å¦‚æœæ¡ˆä»¶ä»åœ¨å®¡ç†ä¸­ï¼Œæ³¨æ˜"å®¡ç†ä¸­"
   - å¦‚æœæœªæåŠç»“æœï¼Œå¡«å†™"æœªçŸ¥"

ã€è¾“å‡ºè¦æ±‚ã€‘
- å¿…é¡»ä»¥çº¯ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown æ ‡è®°æˆ–é¢å¤–è¯´æ˜
- æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å¡«å†™
- Process å­—æ®µå¿…é¡»ä¸¥æ ¼ä½¿ç”¨5ä¸ªæ ‡é¢˜ï¼šã€é£é™©ç”»åƒã€‘ã€ã€èˆå¼Šæ‰‹æ³•(MO)ã€‘ã€ã€çº¢æ——æŒ‡æ ‡(Red Flags)ã€‘ã€ã€æ ¸æŸ¥æ‰‹æ®µå»ºè®®ã€‘ã€ã€æ ¸ä¿/é£æ§å¯ç¤ºã€‘
- Process å­—æ®µç¦æ­¢ä½¿ç”¨æè¿°æ€§æ–‡å­—ï¼Œåªè¾“å‡ºç»“æ„åŒ–å†…å®¹ï¼Œè‡³å°‘ 600 å­—ä»¥ä¸Š
- å­—æ®µåä½¿ç”¨è‹±æ–‡ï¼ˆTime, Region, Characters, Event, Process, Resultï¼‰

ã€JSON æ ¼å¼ç¤ºä¾‹ã€‘
{{
    "Time": "2025-01-15",
    "Region": "ç¾å›½çº½çº¦",
    "Characters": "John Smith, ABCä¿é™©å…¬å¸, XYZåŒ»ç–—ä¸­å¿ƒ",
    "Event": "åŒ»ç–—ä¿é™©æ¬ºè¯ˆ",
    "Process": "ã€é£é™©ç”»åƒã€‘\\næŠ•ä¿æ—¶é—´ï¼š2024å¹´6æœˆ\\nä¿é¢ï¼š50ä¸‡ç¾å…ƒ\\nå‡ºé™©é—´éš”ï¼šæŠ•ä¿å3ä¸ªæœˆ\\n\\nã€èˆå¼Šæ‰‹æ³•(MO)ã€‘\\nä¼ªé€ æµ·å¤–åŒ»ç–—æ”¶æ®\\nè™šå‡è¯Šæ–­è¯æ˜\\n\\nã€çº¢æ——æŒ‡æ ‡(Red Flags)ã€‘\\nåŒ»ç–—è®°å½•æ—¶é—´ä¸å‡ºå…¥å¢ƒè®°å½•ä¸ç¬¦\\nç†èµ”é‡‘é¢å¼‚å¸¸åé«˜\\n\\nã€æ ¸æŸ¥æ‰‹æ®µå»ºè®®ã€‘\\nåŒ»ä¿å¤§æ•°æ®æ¯”å¯¹\\nå‡ºå…¥å¢ƒè®°å½•æ ¸æŸ¥\\n\\nã€æ ¸ä¿/é£æ§å¯ç¤ºã€‘\\nå»ºç«‹æŠ•ä¿å6ä¸ªæœˆå†…å¤§é¢ç†èµ”é¢„è­¦æœºåˆ¶",
    "Result": "è¢«åˆ¤æœ‰æœŸå¾’åˆ‘5å¹´ï¼Œç½šæ¬¾50ä¸‡ç¾å…ƒ"
}}

ç°åœ¨è¯·å¼€å§‹ä¸“ä¸šåˆ†æï¼Œ**ç‰¹åˆ«å…³æ³¨å®¡è®¡ç ´ç»½ (Red Flags) çš„æŒ–æ˜**ï¼š
"""

        try:
            print(f"ğŸ§  [Analyst] æ­£åœ¨åˆ†æå·å®—...")
            print(f"   ğŸ“„ åˆ†æå†…å®¹: {len(markdown_content)} å­—ç¬¦ Markdown å…¨æ–‡")
            print(f"   ğŸ’¡ ç‰¹åˆ«å…³æ³¨ï¼šç ´ç»½ç»†èŠ‚ (The Red Flag) æŒ–æ˜...")
            
            # ä½¿ç”¨ Failover æœºåˆ¶ï¼ˆGemini ä¸»å¼•æ“ + DeepSeek å¤‡ä»½å¼•æ“ï¼‰
            text = self._get_ai_analysis_with_failover(prompt)
            
            if not text:
                print(f"âŒ AI åˆ†æå¤±è´¥ï¼ˆä¸»å¼•æ“å’Œå¤‡ä»½å¼•æ“éƒ½å¤±è´¥ï¼‰")
                return None
            
            text = text.strip()
            
            # æ¸…ç†å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®°
            if text.startswith("```json"):
                text = text[7:]
            if text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()
            
            # æ¸…ç†æ§åˆ¶å­—ç¬¦
            text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
            
            # è§£æ JSON
            case_data = json.loads(text)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['Time', 'Region', 'Characters', 'Event', 'Process', 'Result']
            for field in required_fields:
                if field not in case_data:
                    case_data[field] = "æœªçŸ¥"
            
            # éªŒè¯ Process å­—æ®µé•¿åº¦
            process = case_data.get('Process', '')
            if len(process) < 400:
                case_data['Process'] += "\n\n[æ³¨ï¼šæå–çš„å†…å®¹å¯èƒ½ä¸å®Œæ•´ï¼Œå»ºè®®æŸ¥çœ‹åŸæ–‡]"
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç ´ç»½ç»†èŠ‚
            red_flag_keywords = ['ç ´ç»½', 'å‘ç°', 'è°ƒæŸ¥', 'è¯æ®', 'å¼‚å¸¸', 'red flag', 'detection', 'investigation']
            has_red_flag = any(keyword in process.lower() for keyword in red_flag_keywords)
            if not has_red_flag:
                case_data['Process'] += "\n\nâš ï¸ æ³¨æ„ï¼šæ–‡ä¸­æœªè¯¦ç»†æè¿°ç ´ç»½ç»†èŠ‚æˆ–è°ƒæŸ¥å‘ç°è¿‡ç¨‹ï¼Œä¿¡æ¯ç¼ºå¤±"
            
            # æ·»åŠ å…ƒæ•°æ®
            case_data['Source_URL'] = url
            case_data['Created_at'] = datetime.now().isoformat()
            
            print(f"âœ… [Analyst] åˆ†æå®Œæˆ: {case_data.get('Event', 'æœªçŸ¥äº‹ä»¶')}")
            return case_data
            
        except json.JSONDecodeError as e:
            print(f"âŒ [Analyst] JSON è§£æå¤±è´¥: {str(e)}")
            print(f"   åŸå§‹å“åº”å‰500å­—ç¬¦: {text[:500] if 'text' in locals() else 'N/A'}")
            return None
        except Exception as e:
            print(f"âŒ [Analyst] åˆ†æå¤±è´¥: {str(e)}")
            return None


# ==================== Agent 4: The Validator (æ ¡éªŒå‘˜) ====================

class ValidatorAgent:
    """
    æ ¡éªŒå‘˜ Agentï¼šæ£€æŸ¥æå–ç»“æœçš„å®Œæ•´æ€§
    æ£€æŸ¥6ä¸ªç»´åº¦ï¼Œå¦‚æœç»è¿‡æè¿°å¤ªç®€å•ï¼Œæ ‡è®°ä¸º"ä½è´¨é‡"å¹¶å»ºè®®é‡è¯•
    """
    
    def validate(self, extracted_data: Dict) -> Tuple[bool, Dict]:
        """
        æ ¡éªŒæå–ç»“æœçš„å®Œæ•´æ€§å’Œè´¨é‡
        
        å‚æ•°:
            extracted_data: Analyst æå–çš„ç»“æ„åŒ–æ•°æ®
        
        è¿”å›:
            (is_valid, validation_result) å…ƒç»„
            is_valid: True è¡¨ç¤ºé€šè¿‡éªŒè¯ï¼ŒFalse è¡¨ç¤ºä½è´¨é‡
            validation_result: åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        try:
            print(f"ğŸ” [Validator] æ­£åœ¨æ ¡éªŒæå–ç»“æœè´¨é‡...")
            
            issues = []
            scores = {}
            
            # æ£€æŸ¥6ä¸ªç»´åº¦
            required_fields = ['Time', 'Region', 'Characters', 'Event', 'Process', 'Result']
            
            for field in required_fields:
                value = extracted_data.get(field, '')
                
                # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨ä¸”éç©º
                if not value or value in ['æœªçŸ¥', 'å¾…è¡¥å……', '']:
                    issues.append(f"å­—æ®µ {field} ç¼ºå¤±æˆ–ä¸ºç©º")
                    scores[field] = 0
                else:
                    scores[field] = 1
            
            # ç‰¹åˆ«æ£€æŸ¥ Process å­—æ®µçš„è´¨é‡
            process = extracted_data.get('Process', '')
            process_score = 0
            process_issues = []
            
            if len(process) < 400:
                process_issues.append(f"Process å­—æ®µè¿‡çŸ­ ({len(process)} å­—ç¬¦ï¼Œè¦æ±‚è‡³å°‘ 400 å­—ç¬¦)")
                process_score = 0.3
            elif len(process) < 600:
                process_score = 0.6
            else:
                process_score = 1.0
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸‰ä¸ªå…³é”®éƒ¨åˆ†
            required_parts = ['ä½œæ¡ˆ', 'é€ƒé¿', 'ç ´ç»½']
            for part in required_parts:
                if part not in process:
                    process_issues.append(f"Process ç¼ºå°‘ '{part}' éƒ¨åˆ†")
                    process_score = max(0, process_score - 0.2)
            
            # æ£€æŸ¥ç ´ç»½ç»†èŠ‚
            red_flag_keywords = ['ç ´ç»½', 'å‘ç°', 'è°ƒæŸ¥', 'è¯æ®', 'å¼‚å¸¸', 'red flag']
            has_red_flag = any(keyword in process.lower() for keyword in red_flag_keywords)
            if not has_red_flag or 'ä¿¡æ¯ç¼ºå¤±' in process:
                process_issues.append("Process ç¼ºå°‘ç ´ç»½ç»†èŠ‚ (The Red Flag)")
                process_score = max(0, process_score - 0.3)
            
            if process_issues:
                issues.extend(process_issues)
            
            scores['Process'] = process_score
            
            # è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°
            overall_score = sum(scores.values()) / len(scores)
            
            # åˆ¤æ–­æ˜¯å¦é€šè¿‡éªŒè¯ï¼ˆæ€»åˆ† >= 0.7 ä¸” Process >= 0.6ï¼‰
            is_valid = overall_score >= 0.7 and process_score >= 0.6
            
            validation_result = {
                'is_valid': is_valid,
                'overall_score': overall_score,
                'process_score': process_score,
                'scores': scores,
                'issues': issues,
                'suggestions': []
            }
            
            if not is_valid:
                if process_score < 0.6:
                    validation_result['suggestions'].append("Process å­—æ®µè´¨é‡ä¸è¶³ï¼Œå»ºè®®é‡è¯•ä¸‹ä¸€ä¸ªé“¾æ¥")
                if overall_score < 0.7:
                    validation_result['suggestions'].append("æ•´ä½“è´¨é‡ä¸è¶³ï¼Œå»ºè®®é‡æ–°æå–")
            
            if is_valid:
                print(f"âœ… [Validator] éªŒè¯é€šè¿‡ (è´¨é‡åˆ†æ•°: {overall_score:.2f}, Process: {process_score:.2f})")
            else:
                print(f"âš ï¸ [Validator] éªŒè¯æœªé€šè¿‡ (è´¨é‡åˆ†æ•°: {overall_score:.2f}, Process: {process_score:.2f})")
                print(f"   é—®é¢˜: {len(issues)} ä¸ª")
                for issue in issues[:3]:
                    print(f"   - {issue}")
            
            return is_valid, validation_result
            
        except Exception as e:
            print(f"âš ï¸ [Validator] éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
            # å‡ºé”™æ—¶é»˜è®¤é€šè¿‡ï¼Œä¸é˜»å¡æµç¨‹
            return True, {'error': str(e), 'is_valid': True}


# ==================== æŸ¥é‡æœºåˆ¶ ====================

def calculate_similarity(str1: str, str2: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰"""
    return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()


def check_duplicate(url: str, title: str = "") -> Tuple[bool, Optional[str]]:
    """
    æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼çš„æ¡ˆä¾‹ï¼ˆåŸºäº URL æˆ–æ ‡é¢˜ç›¸ä¼¼åº¦ï¼‰
    
    å‚æ•°:
        url: æ¡ˆä¾‹ URL
        title: æ¡ˆä¾‹æ ‡é¢˜
    
    è¿”å›:
        (is_duplicate, reason) å…ƒç»„
        is_duplicate: True è¡¨ç¤ºé‡å¤
        reason: é‡å¤åŸå› 
    """
    if not supabase:
        return False, None
    
    try:
        # æ–¹æ³•1: æ£€æŸ¥ URL æ˜¯å¦å®Œå…¨ä¸€è‡´
        result = supabase.table('fraud_cases').select('id, source_url, event').eq('source_url', url).execute()
        if result.data and len(result.data) > 0:
            return True, "URL å®Œå…¨åŒ¹é…"
        
        # æ–¹æ³•2: å¦‚æœæä¾›äº†æ ‡é¢˜ï¼Œæ£€æŸ¥æ ‡é¢˜ç›¸ä¼¼åº¦
        if title:
            all_cases = supabase.table('fraud_cases').select('id, event, source_url').limit(100).execute()
            
            if all_cases.data:
                for existing_case in all_cases.data:
                    existing_title = existing_case.get('event', '')
                    
                    # è®¡ç®—æ ‡é¢˜ç›¸ä¼¼åº¦
                    similarity = calculate_similarity(title, existing_title)
                    
                    # å¦‚æœç›¸ä¼¼åº¦è¶…è¿‡ 85%ï¼Œè®¤ä¸ºæ˜¯é‡å¤
                    if similarity > 0.85:
                        return True, f"æ ‡é¢˜ç›¸ä¼¼åº¦ {similarity:.2%}"
        
        return False, None
        
    except Exception as e:
        print(f"âš ï¸ æŸ¥é‡å¤±è´¥: {str(e)}")
        return False, None


# ==================== æ•°æ®åº“æ“ä½œ ====================

def save_to_supabase(case_data: Dict, validation_result: Optional[Dict] = None) -> bool:
    """å°†æ¡ˆä¾‹æ•°æ®ä¿å­˜åˆ° Supabase æ•°æ®åº“"""
    if not supabase:
        print(f"âŒ Supabase æœªåˆå§‹åŒ–")
        return False
    
    try:
        insert_data = {
            'time': case_data.get('Time', 'æœªçŸ¥'),
            'region': case_data.get('Region', 'æœªçŸ¥'),
            'characters': case_data.get('Characters', 'æœªçŸ¥'),
            'event': case_data.get('Event', 'æœªçŸ¥'),
            'process': case_data.get('Process', 'æœªçŸ¥'),
            'result': case_data.get('Result', 'æœªçŸ¥'),
            'source_url': case_data.get('Source_URL', ''),
            'created_at': case_data.get('Created_at', datetime.now().isoformat())
        }
        
        # å¦‚æœæœ‰éªŒè¯ç»“æœï¼Œæ·»åŠ è´¨é‡åˆ†æ•°æ ‡è®°
        if validation_result:
            overall_score = validation_result.get('overall_score', 1.0)
            if overall_score < 1.0:
                insert_data['process'] += f" [è´¨é‡åˆ†æ•°: {overall_score:.2f}]"
        
        result = supabase.table('fraud_cases').insert(insert_data).execute()
        
        if result.data:
            print(f"âœ… æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“: {insert_data['event']}")
            return True
        else:
            print(f"âš ï¸ ä¿å­˜å¤±è´¥: æ— è¿”å›æ•°æ®")
            return False
            
    except Exception as e:
        print(f"âŒ ä¿å­˜åˆ° Supabase å¤±è´¥: {str(e)}")
        return False


# ==================== æ·±åº¦ç ”ç©¶æµç¨‹ ====================

def deep_research_flow(search_results: List[Dict], max_cases: int = 3) -> Dict:
    """
    æ·±åº¦ç ”ç©¶æµç¨‹ï¼šä¸²è” Scout -> Researcher -> Analyst -> Validator
    
    å‚æ•°:
        search_results: Scout æœç´¢çš„ç»“æœåˆ—è¡¨
        max_cases: æœ€å¤šå¤„ç†çš„æ¡ˆä¾‹æ•°é‡
    
    è¿”å›:
        å¤„ç†ç»“æœç»Ÿè®¡å­—å…¸
    """
    print("\n" + "=" * 70)
    print("ğŸ”„ å¼€å§‹æ·±åº¦ç ”ç©¶æµç¨‹")
    print("=" * 70)
    
    # åˆå§‹åŒ–å„ä¸ª Agent
    researcher = ResearcherAgent(firecrawl_app)
    analyst = AnalystAgent(GEMINI_API_KEY)
    validator = ValidatorAgent()
    
    # é€‰æ‹©å‰ max_cases ä¸ªé«˜è´¨é‡é“¾æ¥
    top_links = search_results[:max_cases]
    
    saved_count = 0
    skipped_count = 0
    failed_count = 0
    retry_count = 0
    
    for i, search_result in enumerate(top_links, 1):
        url = search_result['url']
        title = search_result['title']
        
        print(f"\n{'='*70}")
        print(f"ğŸ“¦ å¤„ç†æ¡ˆä¾‹ {i}/{len(top_links)}")
        print(f"{'='*70}")
        print(f"ğŸ”— URL: {url[:80]}...")
        print(f"ğŸ“„ æ ‡é¢˜: {title}")
        
        # æŸ¥é‡æ£€æŸ¥
        is_duplicate, reason = check_duplicate(url, title)
        if is_duplicate:
            print(f"â­ï¸  è·³è¿‡: é‡å¤æ¡ˆä¾‹ ({reason})")
            skipped_count += 1
            continue
        
        # ========== Step 1: Researcher Agent ==========
        print(f"\nğŸ“¥ [Step 1] Researcher Agent - æ·±åº¦æŠ“å–å…¨æ–‡...")
        scraped_data = researcher.scrape_url(url)
        
        if not scraped_data:
            print(f"âŒ Researcher å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¡ˆä¾‹")
            failed_count += 1
            continue
        
        markdown_content = scraped_data['markdown_content']
        print(f"âœ… Researcher å®Œæˆï¼šè·å– {scraped_data['content_length']} å­—ç¬¦ Markdown å…¨æ–‡")
        
        # ========== Step 2: Analyst Agent ==========
        print(f"\nğŸ§  [Step 2] Analyst Agent - æ·±åº¦åˆ†ææå–ä¿¡æ¯...")
        print(f"   ğŸ’¡ ç‰¹åˆ«å…³æ³¨ï¼šç ´ç»½ç»†èŠ‚ (The Red Flag) æŒ–æ˜...")
        extracted_data = analyst.analyze(url, title, markdown_content)
        
        if not extracted_data:
            print(f"âŒ Analyst å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¡ˆä¾‹")
            failed_count += 1
            continue
        
        print(f"âœ… Analyst å®Œæˆï¼šæˆåŠŸæå–ç»“æ„åŒ–ä¿¡æ¯")
        
        # ========== Step 3: Validator Agent ==========
        print(f"\nğŸ” [Step 3] Validator Agent - æ ¡éªŒæå–è´¨é‡...")
        is_valid, validation_result = validator.validate(extracted_data)
        
        if not is_valid:
            print(f"âš ï¸ Validator æœªé€šè¿‡éªŒè¯ï¼šè´¨é‡ä¸è¶³")
            
            # å¦‚æœæ˜¯ Process å­—æ®µè´¨é‡ä¸è¶³ï¼Œæ ‡è®°ä¸ºé‡è¯•
            process_score = validation_result.get('process_score', 0)
            if process_score < 0.6:
                print(f"   ğŸ’¡ å»ºè®®ï¼šProcess å­—æ®µè´¨é‡ä¸è¶³ï¼Œå¯ä»¥é‡è¯•ä¸‹ä¸€ä¸ªé“¾æ¥")
                retry_count += 1
                # å¯ä»¥é€‰æ‹©ï¼š1) è·³è¿‡æ­¤æ¡ˆä¾‹ 2) æ ‡è®°ä¿å­˜ä½†æ ‡æ³¨ä½è´¨é‡
                # å½“å‰ç­–ç•¥ï¼šæ ‡è®°ä¿å­˜ä½†æ ‡æ³¨ä½è´¨é‡
                print(f"   ğŸ“ æ ‡è®°ä¸ºä½è´¨é‡æ¡ˆä¾‹ï¼Œä½†ä»ä¿å­˜åˆ°æ•°æ®åº“")
            else:
                failed_count += 1
                continue
        
        # ========== ä¿å­˜åˆ°æ•°æ®åº“ ==========
        print(f"\nğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
        if save_to_supabase(extracted_data, validation_result):
            saved_count += 1
            print(f"âœ… æ¡ˆä¾‹ä¿å­˜æˆåŠŸ")
        else:
            failed_count += 1
        
        # é¿å… API é™æµ
        if i < len(top_links):
            wait_time = 15
            print(f"\nâ³ ç­‰å¾… {wait_time} ç§’ä»¥é¿å… API é™æµ...")
            time.sleep(wait_time)
    
    return {
        'saved': saved_count,
        'skipped': skipped_count,
        'failed': failed_count,
        'retry': retry_count,
        'total_processed': len(top_links)
    }


# ==================== ä¸»æµç¨‹ ====================

def main():
    """ä¸»å‡½æ•°ï¼šæ·±åº¦åä½œæµç¨‹"""
    print("=" * 70)
    print("ğŸš€ GIFIA v3.0 - å…¨çƒä¿é™©æ¬ºè¯ˆæƒ…æŠ¥æŠ“å–ï¼ˆæ·±åº¦åä½œæ¨¡å¼ï¼‰")
    print(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # éªŒè¯å¿…è¦çš„ API Key
    if not all([TAVILY_API_KEY, GEMINI_API_KEY, SUPABASE_URL, SUPABASE_KEY]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ API Key æˆ–é…ç½®")
        print("è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡: TAVILY_API_KEY, GEMINI_API_KEY, SUPABASE_URL, SUPABASE_KEY")
        return
    
    if not FIRECRAWL_API_KEY:
        print("âŒ é”™è¯¯: FIRECRAWL_API_KEY æœªè®¾ç½®ï¼ˆå¿…éœ€ï¼‰")
        print("è¯·è®¾ç½® FIRECRAWL_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    # ========== Step 1: Scout Agent ==========
    print("\n" + "=" * 70)
    print("ğŸ“¡ Step 1: Scout Agent - é«˜çº§æœç´¢")
    print("=" * 70)
    
    scout = ScoutAgent(tavily_client)
    search_results = scout.search(max_results=15)
    
    if not search_results:
        print("âš ï¸ æœªæœç´¢åˆ°ä»»ä½•ç¬¦åˆæ¡ä»¶çš„æ¡ˆä¾‹ï¼Œç¨‹åºé€€å‡º")
        return
    
    # é€‰æ‹©å‰3ä¸ªé«˜è´¨é‡é“¾æ¥è¿›è¡Œæ·±åº¦ç ”ç©¶
    print(f"\nâœ… Scout å®Œæˆï¼šé€‰æ‹©å‰ 3 ä¸ªé«˜è´¨é‡æ¡ˆä¾‹è¿›è¡Œæ·±åº¦ç ”ç©¶")
    
    # ========== Step 2-4: æ·±åº¦ç ”ç©¶æµç¨‹ ==========
    results = deep_research_flow(search_results, max_cases=3)
    
    # ========== è¾“å‡ºç»Ÿè®¡ä¿¡æ¯ ==========
    print("\n" + "=" * 70)
    print("ğŸ“Š æ·±åº¦ç ”ç©¶å®Œæˆç»Ÿè®¡")
    print("=" * 70)
    print(f"âœ… æˆåŠŸä¿å­˜: {results['saved']} ä¸ªæ¡ˆä¾‹")
    print(f"â­ï¸  è·³è¿‡ï¼ˆé‡å¤ï¼‰: {results['skipped']} ä¸ªæ¡ˆä¾‹")
    print(f"âš ï¸  ä½è´¨é‡é‡è¯•: {results['retry']} ä¸ªæ¡ˆä¾‹")
    print(f"âŒ å¤±è´¥: {results['failed']} ä¸ªæ¡ˆä¾‹")
    print(f"ğŸ“ˆ æ€»è®¡å¤„ç†: {results['total_processed']} ä¸ªé«˜è´¨é‡æ¡ˆä¾‹")
    print(f"ğŸ” Scout æœç´¢: {len(search_results)} ä¸ªç»“æœ")
    print("=" * 70)


if __name__ == "__main__":
    main()
